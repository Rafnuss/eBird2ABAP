{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to compute ABAP card from eBird data\n",
    "\n",
    "The aims of this code is to produce a dataset of ABAP full protocol card equivalent from the eBird EBD dataset.\n",
    "\n",
    "## Overview rational of the approach\n",
    "\n",
    "A card is uniquely defined by three elements: pentad*code, user_id, and date of the first day of the 5 days. We therefore use the `card_id = {pentad}*{observer}\\_{date}`. From these three variables, it is possible to find all checklists that belong to it.\n",
    "\n",
    "The aim here is to build a list of **valid** cards for which will then be used to find the `checklist_id` that belongs to each valid card and then finally compute the card info from the list of checklists.\n",
    "\n",
    "Pentad: we need to assign for each checklist its pentad and check that the distance traveled is within the boundary of the pentad.\n",
    "User_id is quite straightforward to build.\n",
    "Date: much more challenging. See below for details.\n",
    "\n",
    "General steps:\n",
    "\n",
    "1. Construct the list of valid cards\n",
    "   1. Group raw EBD data to checklist level information (merge shared checklist)\n",
    "   2. Filter checklists which could make a valid card\n",
    "      1. Keep only complete checklists\n",
    "      2. Keep only checklists with `Historical`, `Stationary`, `Traveling`, `Incidental` protocol\n",
    "      3. Keep only checklists within the pentad, that is,\n",
    "         1. Exclude checklists with `historical` protocol that don't have a distance.\n",
    "         2. Exclude checklists with distance greater than the distance from center of checklist to closest pentad limit (accept some overlap with a correction factor).\n",
    "      4. Keep only checklists with duration greated than 0.\n",
    "   3. Group checklists by date (named `checkday` later on)\n",
    "   4. Group checklists into pentad_observer group so that we only have to loop through the date to find valid card\n",
    "   5. Preliminary filter to eliminate all pentad_observer for which the sum over the entire period does not lead to 2h\n",
    "   6. For each remaining pentad_observer, apply the function `checkday_pentad_observer()`, which,\n",
    "      1. Compute the temporal distance between all checkday and check if they are within 5 days.\n",
    "      2. Loop through all checkday,\n",
    "         1. Compute the total duration of all checkdays within temporal distance\n",
    "            1. If valid, create the card_id and apply it to all checkday. Iterate to the first next checkday that was not within temporal distance\n",
    "            2. If invalid, iterate to the next checkday\n",
    "2. Create the card data\n",
    "   1. For each valid card, aggregate all checklists which are (1) within pentad, (2) same observer and (3) day within the 5 day period. This include more checklists than used to construct the list of valid cards\n",
    "3. Add species level information to cards\n",
    "   1. Add sequence information based on first occurance on checklist.\n",
    "4. Export in JSON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General set-up\n",
    "\n",
    "### Load library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "import requests\n",
    "import tarfile\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "sys.path.append(\"../functions\")\n",
    "\n",
    "from latlng2pentad import latlng2pentad\n",
    "from pentad2latlng import pentad2latlng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the latest EBD AFRICA data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code doesn't work as you need to sign in into to get access to the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate previous month and year\n",
    "today = datetime.date.today()\n",
    "last_month = today.replace(day=1) - datetime.timedelta(days=1)\n",
    "year = last_month.strftime(\"%Y\")\n",
    "month = last_month.strftime(\"%b\")\n",
    "\n",
    "# Construct URL and filename\n",
    "url = f\"https://ebird.org/data/download?p=prepackaged/ebd_AFR_rel{month}-{year}.tar\"\n",
    "filename = os.path.basename(url)\n",
    "filepath = os.path.join(\"../data/eBird/\", filename)\n",
    "\n",
    "# with open(filepath, \"wb\") as f:\n",
    "#     f.write(requests.get(url).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tarfile.open(filepath, \"r\") as tar:\n",
    "#     tar.extractall(f\"../data/eBird/ebd_AFR_rel{month}-{year}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the EBD file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2024\"\n",
    "month = \"Jul\"\n",
    "\n",
    "# file = \"../data/eBird/ebd_AFR_rel{month}-{year}/ebd_AFR_rel{month}-{year}.txt.gz\"\n",
    "file = f\"../data/eBird/ebd_AFR_rel{month}-{year}/ebd_AFR_rel{month}-{year}.txt.gz\"\n",
    "# file = \"../data/eBird/ebd_AFR_relJul-2024/ebd_AFR_relJul-2024.txt.gz\"\n",
    "\n",
    "\n",
    "# For country specific EBD file, you can use:\n",
    "# cntr = \"KE\"\n",
    "# file = \"../data/eBird/chk_{cntr}_relAug-2022/ebd_{cntr}_relAug-2022.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ebd0 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\n\u001b[1;32m      2\u001b[0m     file,\n\u001b[1;32m      3\u001b[0m     delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     usecols\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAMPLING EVENT IDENTIFIER\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSCIENTIFIC NAME\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCATEGORY\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLATITUDE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLONGITUDE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOBSERVATION DATE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTIME OBSERVATIONS STARTED\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPROTOCOL TYPE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDURATION MINUTES\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEFFORT DISTANCE KM\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALL SPECIES REPORTED\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOBSERVER ID\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     ],\n\u001b[1;32m     18\u001b[0m     parse_dates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOBSERVATION DATE\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     19\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m         nrows\n\u001b[1;32m   1925\u001b[0m     )\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[0;32m---> 68\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m(byte_view))\n\u001b[1;32m     69\u001b[0m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/gzip.py:507\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# Read a chunk of data from the file\u001b[39;00m\n\u001b[1;32m    505\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread(io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE)\n\u001b[0;32m--> 507\u001b[0m uncompress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39mdecompress(buf, size)\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mprepend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ebd0 = pd.read_csv(\n",
    "    file,\n",
    "    delimiter=\"\\t\",\n",
    "    usecols=[\n",
    "        \"SAMPLING EVENT IDENTIFIER\",\n",
    "        \"SCIENTIFIC NAME\",\n",
    "        \"CATEGORY\",\n",
    "        \"LATITUDE\",\n",
    "        \"LONGITUDE\",\n",
    "        \"OBSERVATION DATE\",\n",
    "        \"TIME OBSERVATIONS STARTED\",\n",
    "        \"PROTOCOL TYPE\",\n",
    "        \"DURATION MINUTES\",\n",
    "        \"EFFORT DISTANCE KM\",\n",
    "        \"ALL SPECIES REPORTED\",\n",
    "        \"OBSERVER ID\",\n",
    "    ],\n",
    "    parse_dates=[\"OBSERVATION DATE\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebd = ebd0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create OBSERVATIONDATETIME by combining date and time\n",
    "tmp = ebd[\"TIME OBSERVATIONS STARTED\"].fillna(\"00:00:00\")\n",
    "ebd[\"OBSERVATION DATETIME\"] = pd.to_datetime(\n",
    "    ebd[\"OBSERVATION DATE\"].dt.strftime(\"%Y-%m-%d\") + \" \" + tmp,\n",
    "    format=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "# Sort by date: Important to have for filtering duplicate card-adu and needed for sequence\n",
    "ebd.sort_values(by=\"OBSERVATION DATETIME\", inplace=True)\n",
    "\n",
    "# Keep only species category\n",
    "# ebd0[[\"COMMONNAME\", \"SCIENTIFIC NAME\", \"CATEGORY\"]].drop_duplicates().to_csv(\"species_list_ebird.csv\", index=False)\n",
    "\n",
    "# Keep some spuh which can be matched to an ADU\n",
    "# spuh_keep = pd.read_csv(\"data/spuh_keep.csv\", dtype=str)\n",
    "# ebd0 = ebd0[(~ebd0[\"CATEGORY\"].isin([\"spuh\", \"slash\"])) | ebd0[\"SCIENTIFIC NAME\"].isin(spuh_keep[\"Clements--scientific_name\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Avibase taxon concept id and species code\n",
    "species_ebird = pd.read_excel(\"../data/species_list/ebird_taxonomy_v2023.xlsx\").rename(\n",
    "    columns={\n",
    "        \"SCI_NAME\": \"SCIENTIFIC NAME\",\n",
    "        \"TAXON_CONCEPT_ID\": \"TAXON CONCEPT\",\n",
    "        \"SPECIES_CODE\": \"SPECIES CODE\",\n",
    "    }\n",
    ")\n",
    "ebd = pd.merge(\n",
    "    ebd,  # .loc[:,['OBSERVER ID', 'PENTAD', \"SAMPLING EVENT IDENTIFIER\", \"OBSERVATION DATE\"]],\n",
    "    species_ebird[[\"SCIENTIFIC NAME\", \"TAXON CONCEPT\", \"SPECIES CODE\"]],\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read matched_species data. See species_match.ipynb\n",
    "matched_species = pd.read_csv(\"../data/species_list/matched_species.csv\")\n",
    "\n",
    "ebd = pd.merge(\n",
    "    ebd,  # .loc[:,['OBSERVER ID', 'PENTAD', \"SAMPLING EVENT IDENTIFIER\", \"OBSERVATION DATE\"]],\n",
    "    matched_species[[\"TAXON CONCEPT\", \"ADU\"]].drop_duplicates(subset=\"TAXON CONCEPT\"),\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We still have 973 unmatched taxons, corresponding to 4% of our data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SCIENTIFIC NAME        \n",
       "Icthyophaga vocifer        90635\n",
       "Spermestes cucullata       82830\n",
       "Zapornia flavirostra       51197\n",
       "Lanius melanoleucus        34528\n",
       "Ardea brachyrhyncha        31084\n",
       "                           ...  \n",
       "Egretta novaehollandiae        1\n",
       "Aegithalos caudatus            1\n",
       "Zenaida auriculata             1\n",
       "Ducula bicolor                 1\n",
       "Cacatua sulphurea              1\n",
       "Name: count, Length: 973, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmatched = (\n",
    "    ebd[ebd[\"ADU\"].isna()][[\"SCIENTIFIC NAME\"]].value_counts().sort_values(ascending=0)\n",
    ")\n",
    "print(\n",
    "    f\"We still have {len(unmatched)} unmatched taxons, corresponding to {round(sum(unmatched)/len(ebd)*100)}% of our data\"\n",
    ")\n",
    "unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# data: 21190167\n",
      "# Checklists: 1262874\n",
      "# Species: 3127\n"
     ]
    }
   ],
   "source": [
    "print(f\"# data: {len(ebd)}\")\n",
    "print(f\"# Checklists: {len(ebd['SAMPLING EVENT IDENTIFIER'].unique())}\")\n",
    "print(f\"# Species: {len(ebd['SCIENTIFIC NAME'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build checklist dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk = ebd[\n",
    "    [\n",
    "        \"SAMPLING EVENT IDENTIFIER\",\n",
    "        \"LATITUDE\",\n",
    "        \"LONGITUDE\",\n",
    "        \"OBSERVATION DATE\",\n",
    "        \"OBSERVATION DATETIME\",\n",
    "        \"PROTOCOL TYPE\",\n",
    "        \"DURATION MINUTES\",\n",
    "        \"EFFORT DISTANCE KM\",\n",
    "        \"ALL SPECIES REPORTED\",\n",
    "        \"OBSERVER ID\",\n",
    "    ]\n",
    "].drop_duplicates()\n",
    "\n",
    "# Sort by date\n",
    "chk.sort_values(by=\"OBSERVATION DATETIME\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1262874"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For some shared checklist some variable are different for the same sampling event.\n",
    "# chk[chk[\"SAMPLING EVENT IDENTIFIER\"].duplicated(keep=False)].sort_values(by=\"SAMPLING EVENT IDENTIFIER\")\n",
    "# ebd0[ebd0[\"SAMPLING EVENT IDENTIFIER\"] == \"S97700871\"]\n",
    "chk = chk.drop_duplicates(\"SAMPLING EVENT IDENTIFIER\").reset_index(drop=True)\n",
    "len(chk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter protocol\n",
    "chk[\"KEEP PROTOCOL\"] = chk[\"PROTOCOL TYPE\"].isin(\n",
    "    [\"Historical\", \"Incidental\", \"Stationary\", \"Traveling\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pentad\n",
    "# Assign the pentad to all checklists based on their location\n",
    "chk[\"PENTAD\"] = latlng2pentad(chk[\"LATITUDE\"], chk[\"LONGITUDE\"])\n",
    "\n",
    "# Retrieve the lat, lon center of the assigned pentad\n",
    "lat, lon = pentad2latlng(chk[\"PENTAD\"])\n",
    "\n",
    "# Convert effort distance of the checklisst into degree lat-lon\n",
    "effort_distance_lat = 180 / np.pi / 6371 * chk[\"EFFORT DISTANCE KM\"]\n",
    "effort_distance_lon = (\n",
    "    180 / np.pi / 6371 / np.cos(np.radians(chk[\"LATITUDE\"])) * chk[\"EFFORT DISTANCE KM\"]\n",
    ")\n",
    "\n",
    "# Compute the distance from the center of the pentad (lat,lon) to the max distance possible if the observer traveled in the worst possible direction (i.e., to the closest eadge of the pentad)\n",
    "# We relax a little bit the assumption of moving on the straight line to the edge of the pentad by applying a correction factor\n",
    "corr_straight_line = 0.8\n",
    "dist_lat = np.abs(lat - chk[\"LATITUDE\"]) + effort_distance_lat * corr_straight_line\n",
    "dist_lon = np.abs(lon - chk[\"LONGITUDE\"]) + effort_distance_lon * corr_straight_line\n",
    "\n",
    "# The maximum distance allowed for the checklist to be considered valid is half of a pentad resolution (5/60°)\n",
    "# We accept that the checklist might have traveled a bit more that this distance\n",
    "corr_overlap = 1.2  # allow for a 20% overlap\n",
    "max_dist = (5 / 60 / 2) * corr_overlap\n",
    "\n",
    "chk[\"KEEP PENTAD\"] = (dist_lat < max_dist) & (dist_lon < max_dist)\n",
    "\n",
    "# Filter historical checklists which have no distance\n",
    "chk.loc[\n",
    "    (chk[\"PROTOCOL TYPE\"] == \"Historical\") & chk[\"EFFORT DISTANCE KM\"].isna(),\n",
    "    \"KEEP PENTAD\",\n",
    "] = False\n",
    "\n",
    "# Filter historical checklists which have no distance\n",
    "chk.loc[\n",
    "    chk[\"EFFORT DISTANCE KM\"].isna(),\n",
    "    \"KEEP PENTAD\",\n",
    "] = True\n",
    "\n",
    "chk.loc[\n",
    "    (chk[\"PROTOCOL TYPE\"] == \"Historical\") & chk[\"EFFORT DISTANCE KM\"].isna(),\n",
    "    \"KEEP PENTAD\",\n",
    "] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all possible valid card\n",
    "\n",
    "Cards are considered to be full protocol if the sum of durations of the underlying checklists exceed 2 hours over the next rolling 5 days.\n",
    "In this section, we first indentify which checklists can create a valid full card.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of all checklists which contribute to the 2hr rule. Note that we will still use \"non-valid\" checklists later as their species still contribute to the card.\n",
    "valid_id = (\n",
    "    chk[\"KEEP PENTAD\"]\n",
    "    & chk[\"KEEP PROTOCOL\"]\n",
    "    & (chk[\"DURATION MINUTES\"] > 0)\n",
    "    & chk[\"ALL SPECIES REPORTED\"]\n",
    ")\n",
    "\n",
    "# Filter for valid checklist and create in a smaller table\n",
    "check = chk.loc[\n",
    "    valid_id, [\"PENTAD\", \"OBSERVER ID\", \"OBSERVATION DATE\", \"DURATION MINUTES\"]\n",
    "]\n",
    "\n",
    "# Combine checklists made by the same observer, pentad, and day. This is an intermediate step which enables us to grid the 5 days windows more easily\n",
    "checkday = (\n",
    "    check.groupby([\"PENTAD\", \"OBSERVER ID\", \"OBSERVATION DATE\"])\n",
    "    .agg({\"DURATION MINUTES\": \"sum\"})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Sort the checklist by date\n",
    "checkday.sort_values(by=[\"OBSERVATION DATE\"], inplace=True)\n",
    "\n",
    "# Create additional columns\n",
    "checkday[\"pentad_observer\"] = checkday[\"PENTAD\"] + \"_\" + checkday[\"OBSERVER ID\"]\n",
    "checkday[\"pentad_observer_date\"] = (\n",
    "    checkday[\"PENTAD\"]\n",
    "    + \"_\"\n",
    "    + checkday[\"OBSERVER ID\"].str[3:]\n",
    "    + \"_\"\n",
    "    + checkday[\"OBSERVATION DATE\"].dt.strftime(\"%Y%m%d\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a first filter to eliminate all pentad_observer witout sufficient total duration time. (Aim is to just reduce the computation later)\n",
    "pentad_observer_duration = checkday.groupby([\"pentad_observer\"])[\n",
    "    \"DURATION MINUTES\"\n",
    "].sum()\n",
    "pentad_observer_duration_index = pentad_observer_duration[\n",
    "    pentad_observer_duration >= 2 * 60\n",
    "].index\n",
    "checkday_long = checkday[\n",
    "    checkday[\"pentad_observer\"].isin(pentad_observer_duration_index)\n",
    "]\n",
    "\n",
    "# Second filter for reducing the test case\n",
    "# pentad_observer_unique = checkday_long[\"pentad_observer\"].unique()\n",
    "# pentad_observer_unique = pentad_observer_unique[0:1000]\n",
    "# checkday_long = checkday_long[checkday_long[\"pentad_observer\"].isin(pentad_observer_unique)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find all pentad with sufficient duration effort (i.e, a sum of 2h over 5 days period), we apply this function for each pentad_observer.\n",
    "def checkday_pentad_observer(df):\n",
    "    df[\"CARD\"] = \"\"\n",
    "    # Build a matrix of distance between all checklists to check if they are close to each other\n",
    "    di = np.abs(\n",
    "        df[\"OBSERVATION DATE\"].values[:, None] - df[\"OBSERVATION DATE\"].values\n",
    "    ) < pd.Timedelta(days=5)\n",
    "    # create duration array to make computation slightly faster\n",
    "    duration = df[\"DURATION MINUTES\"].to_numpy()\n",
    "    # Initie the card array with empty string\n",
    "    # card = np.array(['' for x in range(len(df))], dtype='object')\n",
    "    u = 1\n",
    "    # Loop trough the list of checklists\n",
    "    while u <= len(df):\n",
    "        # Find all neighbord\n",
    "        nb_neighbor = np.sum(di[u - 1, (u - 1) :])\n",
    "        neigh = u + np.arange(0, nb_neighbor) - 1\n",
    "        dur = duration[neigh].sum()\n",
    "        # Check that total duration is more than 2hours, if so add card code (pentad_observer_date) to card array\n",
    "        if dur >= (2 * 60):\n",
    "            df.iloc[neigh, df.columns.get_loc(\"CARD\")] = df.iloc[\n",
    "                u - 1, df.columns.get_loc(\"pentad_observer_date\")\n",
    "            ]\n",
    "        u += nb_neighbor\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function defined above for each pentad-observer at the same time (makes operation much faster)\n",
    "checkday_long_card = (\n",
    "    checkday_long.groupby(\"pentad_observer\")\n",
    "    .apply(checkday_pentad_observer, include_groups=False)\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame of all valid card\n",
    "card_valid = checkday_long_card[\n",
    "    checkday_long_card[\"CARD\"] == checkday_long_card[\"pentad_observer_date\"]\n",
    "][[\"PENTAD\", \"OBSERVER ID\", \"OBSERVATION DATE\", \"CARD\"]]\n",
    "\n",
    "# Sort by card\n",
    "card_valid.sort_values(by=\"CARD\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PENTAD</th>\n",
       "      <th>OBSERVER ID</th>\n",
       "      <th>OBSERVATION DATE</th>\n",
       "      <th>CARD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000_0920</td>\n",
       "      <td>obsr431479</td>\n",
       "      <td>2022-08-10</td>\n",
       "      <td>0000_0920_r431479_20220810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0000_0920</td>\n",
       "      <td>obsr431479</td>\n",
       "      <td>2024-02-18</td>\n",
       "      <td>0000_0920_r431479_20240218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0000_1135</td>\n",
       "      <td>obsr344577</td>\n",
       "      <td>1997-07-22</td>\n",
       "      <td>0000_1135_r344577_19970722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0000_1140</td>\n",
       "      <td>obsr107968</td>\n",
       "      <td>1996-07-08</td>\n",
       "      <td>0000_1140_r107968_19960708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0000_1140</td>\n",
       "      <td>obsr167174</td>\n",
       "      <td>1996-07-08</td>\n",
       "      <td>0000_1140_r167174_19960708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164700</th>\n",
       "      <td>3720c0950</td>\n",
       "      <td>obsr1896095</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>3720c0950_r1896095_20200302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164701</th>\n",
       "      <td>3720c0950</td>\n",
       "      <td>obsr433404</td>\n",
       "      <td>2024-05-29</td>\n",
       "      <td>3720c0950_r433404_20240529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164704</th>\n",
       "      <td>3720c0950</td>\n",
       "      <td>obsr490904</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>3720c0950_r490904_20200302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164705</th>\n",
       "      <td>3720c0950</td>\n",
       "      <td>obsr536040</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>3720c0950_r536040_20200302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164706</th>\n",
       "      <td>4650_3740</td>\n",
       "      <td>obsr293179</td>\n",
       "      <td>2022-01-27</td>\n",
       "      <td>4650_3740_r293179_20220127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62396 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PENTAD  OBSERVER ID OBSERVATION DATE                         CARD\n",
       "4       0000_0920   obsr431479       2022-08-10   0000_0920_r431479_20220810\n",
       "5       0000_0920   obsr431479       2024-02-18   0000_0920_r431479_20240218\n",
       "9       0000_1135   obsr344577       1997-07-22   0000_1135_r344577_19970722\n",
       "10      0000_1140   obsr107968       1996-07-08   0000_1140_r107968_19960708\n",
       "11      0000_1140   obsr167174       1996-07-08   0000_1140_r167174_19960708\n",
       "...           ...          ...              ...                          ...\n",
       "164700  3720c0950  obsr1896095       2020-03-02  3720c0950_r1896095_20200302\n",
       "164701  3720c0950   obsr433404       2024-05-29   3720c0950_r433404_20240529\n",
       "164704  3720c0950   obsr490904       2020-03-02   3720c0950_r490904_20200302\n",
       "164705  3720c0950   obsr536040       2020-03-02   3720c0950_r536040_20200302\n",
       "164706  4650_3740   obsr293179       2022-01-27   4650_3740_r293179_20220127\n",
       "\n",
       "[62396 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Card dataframe by aggregating all checklists\n",
    "\n",
    "We take back `chk` where all checklists (i.e., including the incidentals, stationary, etc...) and find if they contribute to an existing full card.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for checklist to keep: within pentad and and pentad and observer present in the valid card list\n",
    "chk_keep = chk[\n",
    "    (chk[\"KEEP PENTAD\"])\n",
    "    & (\n",
    "        (chk[\"PENTAD\"] + chk[\"OBSERVER ID\"]).isin(\n",
    "            (card_valid[\"PENTAD\"] + card_valid[\"OBSERVER ID\"])\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all possible checklits with the valid card based on observer and pentad.\n",
    "# This will create duplicate checklist with all cards submitted by the same observer, same pentad, but any date\n",
    "chk_card = pd.merge(\n",
    "    chk_keep,  # .loc[:,['OBSERVER ID', 'PENTAD', \"SAMPLING EVENT IDENTIFIER\", \"OBSERVATION DATE\"]],\n",
    "    card_valid,\n",
    "    on=[\"OBSERVER ID\", \"PENTAD\"],\n",
    "    suffixes=(\"_chk\", \"_card\"),\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# Filter the checklist for checklist beeing within the 5 days of the card so that there will be a single checklist-card now\n",
    "duration = (\n",
    "    chk_card[\"OBSERVATION DATE_chk\"] - chk_card[\"OBSERVATION DATE_card\"]\n",
    ").dt.days\n",
    "chk_card = chk_card[(duration >= 0) & (duration < 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cretate the card list with all checklists that belong to it. Compute aggregated value of all checklists\n",
    "card_chk = (\n",
    "    chk_card.groupby(\"CARD\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"SAMPLING EVENT IDENTIFIER\": list,\n",
    "            \"OBSERVATION DATETIME\": [\"min\", \"max\"],\n",
    "            \"DURATION MINUTES\": \"sum\",\n",
    "            \"EFFORT DISTANCE KM\": \"sum\",\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "card_chk.columns = [\"_\".join(col).strip(\"_\") for col in card_chk.columns.values]\n",
    "\n",
    "# merge with the information contained in card_valid\n",
    "card_chk = pd.merge(card_chk, card_valid, on=\"CARD\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve species information per card\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the full dataset to get only the checklist used in the card data\n",
    "ebd_f = ebd.loc[\n",
    "    ebd[\"SAMPLING EVENT IDENTIFIER\"].isin(chk_card[\"SAMPLING EVENT IDENTIFIER\"]),\n",
    "    [\n",
    "        \"SAMPLING EVENT IDENTIFIER\",\n",
    "        \"SCIENTIFIC NAME\",\n",
    "        \"ADU\",\n",
    "        \"OBSERVATION DATETIME\",\n",
    "        \"LATITUDE\",\n",
    "        \"LONGITUDE\",\n",
    "        \"EFFORT DISTANCE KM\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "# Add card_id\n",
    "ebd_f = pd.merge(\n",
    "    ebd_f,\n",
    "    chk_card.loc[:, [\"SAMPLING EVENT IDENTIFIER\", \"CARD\"]],\n",
    "    on=\"SAMPLING EVENT IDENTIFIER\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# Keep a unique list of card-species (remove duplicate species in the same card, keeping the first one in time)\n",
    "ebd_f.sort_values(\n",
    "    by=\"OBSERVATION DATETIME\", inplace=True\n",
    ")  # SHould have been done already above, but necessary for keep=\"first\"\n",
    "\n",
    "ebd_f_u = ebd_f.drop_duplicates(subset=[\"CARD\", \"ADU\"], keep=\"first\").copy()\n",
    "ebd_f_u.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the sequence of records based on datetime entry\n",
    "ebd_f_u[\"SEQ\"] = (\n",
    "    ebd_f_u.groupby(\"CARD\")[\"OBSERVATION DATETIME\"].rank(method=\"min\").astype(int)\n",
    ")\n",
    "# Not sure why, but fillina NA by nothing\n",
    "ebd_f_u[\"EFFORT DISTANCE KM\"] = ebd_f_u[\"EFFORT DISTANCE KM\"].fillna(\"\")\n",
    "\n",
    "# Convert datetime to standard format\n",
    "ebd_f_u[\"OBSERVATION DATETIME\"] = ebd_f_u[\"OBSERVATION DATETIME\"].dt.strftime(\n",
    "    \"%Y-%m-%dT%H:%M:%SZ\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CARD</th>\n",
       "      <th>ADU</th>\n",
       "      <th>SEQ</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>OBSERVATION DATETIME</th>\n",
       "      <th>EFFORT DISTANCE KM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000_0920_r431479_20220810</td>\n",
       "      <td>[3852.0, 385.0, 1152.0, 576.0, 629.0, 510.0, 5...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 10, 10, 10, 10, 10...</td>\n",
       "      <td>[-0.0392179, -0.0392179, -0.0392179, -0.039217...</td>\n",
       "      <td>[9.340437, 9.340437, 9.340437, 9.340437, 9.340...</td>\n",
       "      <td>[2022-08-10T11:55:00Z, 2022-08-10T11:55:00Z, 2...</td>\n",
       "      <td>[0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000_0920_r431479_20240218</td>\n",
       "      <td>[3852.0, 50.0, 394.0, 784.0, 846.0, 1089.0, 35...</td>\n",
       "      <td>[1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[-0.0392179, -0.0392179, -0.0392179, -0.039217...</td>\n",
       "      <td>[9.340437, 9.340437, 9.340437, 9.340437, 9.340...</td>\n",
       "      <td>[2024-02-18T12:20:00Z, 2024-02-18T12:20:00Z, 2...</td>\n",
       "      <td>[, , , , 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000_1135_r344577_19970722</td>\n",
       "      <td>[3888.0, 306.0, 283.0, 246.0, 394.0]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>[-0.0686645, -0.0686645, -0.0686645, -0.068664...</td>\n",
       "      <td>[11.6070557, 11.6070557, 11.6070557, 11.607055...</td>\n",
       "      <td>[1997-07-22T11:00:00Z, 1997-07-22T11:00:00Z, 1...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000_1140_r107968_19960708</td>\n",
       "      <td>[2798.0, 61.0, 113.0, 3180.0, 399.0, 352.0, 36...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[-0.0700264, -0.0700264, -0.0700264, -0.070026...</td>\n",
       "      <td>[11.7131367, 11.7131367, 11.7131367, 11.713136...</td>\n",
       "      <td>[1996-07-08T16:30:00Z, 1996-07-08T16:30:00Z, 1...</td>\n",
       "      <td>[1.609, 1.609, 1.609, 1.609, 1.609, 1.609, 1.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000_1140_r167174_19960708</td>\n",
       "      <td>[57.0, 754.0, 352.0, 1628.0, 399.0, 11491.0, 8...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[-0.0700264, -0.0700264, -0.0700264, -0.070026...</td>\n",
       "      <td>[11.7131367, 11.7131367, 11.7131367, 11.713136...</td>\n",
       "      <td>[1996-07-08T16:30:00Z, 1996-07-08T16:30:00Z, 1...</td>\n",
       "      <td>[1.609, 1.609, 1.609, 1.609, 1.609, 1.609, 1.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62391</th>\n",
       "      <td>3720c0950_r1896095_20200302</td>\n",
       "      <td>[933.0, nan, 9638.0]</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>[37.2771433, 37.2771433, 37.2771433]</td>\n",
       "      <td>[9.8745954, 9.8745954, 9.8745954]</td>\n",
       "      <td>[2020-03-02T07:30:00Z, 2020-03-02T07:30:00Z, 2...</td>\n",
       "      <td>[, , ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62392</th>\n",
       "      <td>3720c0950_r433404_20240529</td>\n",
       "      <td>[2162.0, 940.0, 2742.0, 2838.0, 507.0, 379.0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 11, 11, 13, 13]</td>\n",
       "      <td>[37.2788336, 37.2788336, 37.2788336, 37.278833...</td>\n",
       "      <td>[9.8773313, 9.8773313, 9.8773313, 9.8773313, 9...</td>\n",
       "      <td>[2024-05-29T16:11:00Z, 2024-05-29T16:11:00Z, 2...</td>\n",
       "      <td>[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62393</th>\n",
       "      <td>3720c0950_r490904_20200302</td>\n",
       "      <td>[9638.0, nan, 933.0]</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>[37.2771433, 37.2771433, 37.2771433]</td>\n",
       "      <td>[9.8745954, 9.8745954, 9.8745954]</td>\n",
       "      <td>[2020-03-02T07:30:00Z, 2020-03-02T07:30:00Z, 2...</td>\n",
       "      <td>[, , ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62394</th>\n",
       "      <td>3720c0950_r536040_20200302</td>\n",
       "      <td>[933.0, 9638.0, nan]</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>[37.2771433, 37.2771433, 37.2771433]</td>\n",
       "      <td>[9.8745954, 9.8745954, 9.8745954]</td>\n",
       "      <td>[2020-03-02T07:30:00Z, 2020-03-02T07:30:00Z, 2...</td>\n",
       "      <td>[, , ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62395</th>\n",
       "      <td>4650_3740_r293179_20220127</td>\n",
       "      <td>[36.0, 987.0, 16.0, 12.0, 286.0, 862.0, 4137.0...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-46.9072497, -46.9072497, -46.9072497, -46.90...</td>\n",
       "      <td>[37.7364968, 37.7364968, 37.7364968, 37.736496...</td>\n",
       "      <td>[2022-01-27T10:37:00Z, 2022-01-27T10:37:00Z, 2...</td>\n",
       "      <td>[, , , , , , , , , , , , , , , , , , , , , , ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62396 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              CARD  \\\n",
       "0       0000_0920_r431479_20220810   \n",
       "1       0000_0920_r431479_20240218   \n",
       "2       0000_1135_r344577_19970722   \n",
       "3       0000_1140_r107968_19960708   \n",
       "4       0000_1140_r167174_19960708   \n",
       "...                            ...   \n",
       "62391  3720c0950_r1896095_20200302   \n",
       "62392   3720c0950_r433404_20240529   \n",
       "62393   3720c0950_r490904_20200302   \n",
       "62394   3720c0950_r536040_20200302   \n",
       "62395   4650_3740_r293179_20220127   \n",
       "\n",
       "                                                     ADU  \\\n",
       "0      [3852.0, 385.0, 1152.0, 576.0, 629.0, 510.0, 5...   \n",
       "1      [3852.0, 50.0, 394.0, 784.0, 846.0, 1089.0, 35...   \n",
       "2                   [3888.0, 306.0, 283.0, 246.0, 394.0]   \n",
       "3      [2798.0, 61.0, 113.0, 3180.0, 399.0, 352.0, 36...   \n",
       "4      [57.0, 754.0, 352.0, 1628.0, 399.0, 11491.0, 8...   \n",
       "...                                                  ...   \n",
       "62391                               [933.0, nan, 9638.0]   \n",
       "62392  [2162.0, 940.0, 2742.0, 2838.0, 507.0, 379.0, ...   \n",
       "62393                               [9638.0, nan, 933.0]   \n",
       "62394                               [933.0, 9638.0, nan]   \n",
       "62395  [36.0, 987.0, 16.0, 12.0, 286.0, 862.0, 4137.0...   \n",
       "\n",
       "                                                     SEQ  \\\n",
       "0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 10, 10, 10, 10, 10...   \n",
       "1      [1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "2                                        [1, 1, 1, 1, 1]   \n",
       "3          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "4          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "...                                                  ...   \n",
       "62391                                          [1, 1, 1]   \n",
       "62392     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 11, 11, 13, 13]   \n",
       "62393                                          [1, 1, 1]   \n",
       "62394                                          [1, 1, 1]   \n",
       "62395  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                                LATITUDE  \\\n",
       "0      [-0.0392179, -0.0392179, -0.0392179, -0.039217...   \n",
       "1      [-0.0392179, -0.0392179, -0.0392179, -0.039217...   \n",
       "2      [-0.0686645, -0.0686645, -0.0686645, -0.068664...   \n",
       "3      [-0.0700264, -0.0700264, -0.0700264, -0.070026...   \n",
       "4      [-0.0700264, -0.0700264, -0.0700264, -0.070026...   \n",
       "...                                                  ...   \n",
       "62391               [37.2771433, 37.2771433, 37.2771433]   \n",
       "62392  [37.2788336, 37.2788336, 37.2788336, 37.278833...   \n",
       "62393               [37.2771433, 37.2771433, 37.2771433]   \n",
       "62394               [37.2771433, 37.2771433, 37.2771433]   \n",
       "62395  [-46.9072497, -46.9072497, -46.9072497, -46.90...   \n",
       "\n",
       "                                               LONGITUDE  \\\n",
       "0      [9.340437, 9.340437, 9.340437, 9.340437, 9.340...   \n",
       "1      [9.340437, 9.340437, 9.340437, 9.340437, 9.340...   \n",
       "2      [11.6070557, 11.6070557, 11.6070557, 11.607055...   \n",
       "3      [11.7131367, 11.7131367, 11.7131367, 11.713136...   \n",
       "4      [11.7131367, 11.7131367, 11.7131367, 11.713136...   \n",
       "...                                                  ...   \n",
       "62391                  [9.8745954, 9.8745954, 9.8745954]   \n",
       "62392  [9.8773313, 9.8773313, 9.8773313, 9.8773313, 9...   \n",
       "62393                  [9.8745954, 9.8745954, 9.8745954]   \n",
       "62394                  [9.8745954, 9.8745954, 9.8745954]   \n",
       "62395  [37.7364968, 37.7364968, 37.7364968, 37.736496...   \n",
       "\n",
       "                                    OBSERVATION DATETIME  \\\n",
       "0      [2022-08-10T11:55:00Z, 2022-08-10T11:55:00Z, 2...   \n",
       "1      [2024-02-18T12:20:00Z, 2024-02-18T12:20:00Z, 2...   \n",
       "2      [1997-07-22T11:00:00Z, 1997-07-22T11:00:00Z, 1...   \n",
       "3      [1996-07-08T16:30:00Z, 1996-07-08T16:30:00Z, 1...   \n",
       "4      [1996-07-08T16:30:00Z, 1996-07-08T16:30:00Z, 1...   \n",
       "...                                                  ...   \n",
       "62391  [2020-03-02T07:30:00Z, 2020-03-02T07:30:00Z, 2...   \n",
       "62392  [2024-05-29T16:11:00Z, 2024-05-29T16:11:00Z, 2...   \n",
       "62393  [2020-03-02T07:30:00Z, 2020-03-02T07:30:00Z, 2...   \n",
       "62394  [2020-03-02T07:30:00Z, 2020-03-02T07:30:00Z, 2...   \n",
       "62395  [2022-01-27T10:37:00Z, 2022-01-27T10:37:00Z, 2...   \n",
       "\n",
       "                                      EFFORT DISTANCE KM  \n",
       "0      [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, ...  \n",
       "1      [, , , , 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1....  \n",
       "2                              [1.0, 1.0, 1.0, 1.0, 1.0]  \n",
       "3      [1.609, 1.609, 1.609, 1.609, 1.609, 1.609, 1.6...  \n",
       "4      [1.609, 1.609, 1.609, 1.609, 1.609, 1.609, 1.6...  \n",
       "...                                                  ...  \n",
       "62391                                             [, , ]  \n",
       "62392  [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, ...  \n",
       "62393                                             [, , ]  \n",
       "62394                                             [, , ]  \n",
       "62395     [, , , , , , , , , , , , , , , , , , , , , , ]  \n",
       "\n",
       "[62396 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the species list per card as a cell for vectorized computation\n",
    "card_sp = (\n",
    "    ebd_f_u.groupby(\"CARD\")[\n",
    "        [\n",
    "            \"ADU\",\n",
    "            \"SEQ\",\n",
    "            \"LATITUDE\",\n",
    "            \"LONGITUDE\",\n",
    "            \"OBSERVATION DATETIME\",\n",
    "            \"EFFORT DISTANCE KM\",\n",
    "        ]\n",
    "    ]\n",
    "    .agg(list)\n",
    "    .reset_index()\n",
    ")\n",
    "card_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protocol</th>\n",
       "      <th>ObserverEmail</th>\n",
       "      <th>CardNo</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>Pentad</th>\n",
       "      <th>ObserverNo</th>\n",
       "      <th>TotalHours</th>\n",
       "      <th>Hour1</th>\n",
       "      <th>...</th>\n",
       "      <th>Hour8</th>\n",
       "      <th>Hour9</th>\n",
       "      <th>Hour10</th>\n",
       "      <th>TotalSpp</th>\n",
       "      <th>InclNight</th>\n",
       "      <th>AllHabitats</th>\n",
       "      <th>Checklists</th>\n",
       "      <th>TotalDistance</th>\n",
       "      <th>ObserverNoEbird</th>\n",
       "      <th>records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>kenyabirdmap@naturekenya.org</td>\n",
       "      <td>0000_0920_r431479_20220810</td>\n",
       "      <td>2022-08-10</td>\n",
       "      <td>2022-08-10</td>\n",
       "      <td>11:55</td>\n",
       "      <td>0000_0920</td>\n",
       "      <td>22829</td>\n",
       "      <td>2.68</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[S116860554, S116861241]</td>\n",
       "      <td>2.60</td>\n",
       "      <td>obsr431479</td>\n",
       "      <td>[{'Sequence': 1, 'Latitude': -0.0392179, 'Long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>kenyabirdmap@naturekenya.org</td>\n",
       "      <td>0000_0920_r431479_20240218</td>\n",
       "      <td>2024-02-18</td>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>12:20</td>\n",
       "      <td>0000_0920</td>\n",
       "      <td>22829</td>\n",
       "      <td>3.55</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[S162608678, S162609512, S162830782, S16283088...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>obsr431479</td>\n",
       "      <td>[{'Sequence': 1, 'Latitude': -0.0392179, 'Long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>kenyabirdmap@naturekenya.org</td>\n",
       "      <td>0000_1135_r344577_19970722</td>\n",
       "      <td>1997-07-22</td>\n",
       "      <td>1997-07-22</td>\n",
       "      <td>11:00</td>\n",
       "      <td>0000_1135</td>\n",
       "      <td>22829</td>\n",
       "      <td>2.00</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[S13388886]</td>\n",
       "      <td>1.00</td>\n",
       "      <td>obsr344577</td>\n",
       "      <td>[{'Sequence': 1, 'Latitude': -0.0686645, 'Long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>kenyabirdmap@naturekenya.org</td>\n",
       "      <td>0000_1140_r107968_19960708</td>\n",
       "      <td>1996-07-08</td>\n",
       "      <td>1996-07-08</td>\n",
       "      <td>16:30</td>\n",
       "      <td>0000_1140</td>\n",
       "      <td>22829</td>\n",
       "      <td>3.00</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[S7529043]</td>\n",
       "      <td>1.61</td>\n",
       "      <td>obsr107968</td>\n",
       "      <td>[{'Sequence': 1, 'Latitude': -0.0700264, 'Long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>kenyabirdmap@naturekenya.org</td>\n",
       "      <td>0000_1140_r167174_19960708</td>\n",
       "      <td>1996-07-08</td>\n",
       "      <td>1996-07-08</td>\n",
       "      <td>16:30</td>\n",
       "      <td>0000_1140</td>\n",
       "      <td>22829</td>\n",
       "      <td>3.00</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[S7529228]</td>\n",
       "      <td>1.61</td>\n",
       "      <td>obsr167174</td>\n",
       "      <td>[{'Sequence': 1, 'Latitude': -0.0700264, 'Long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62391</th>\n",
       "      <td>F</td>\n",
       "      <td>kenyabirdmap@naturekenya.org</td>\n",
       "      <td>3720c0950_r1896095_20200302</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>07:30</td>\n",
       "      <td>3720c0950</td>\n",
       "      <td>22829</td>\n",
       "      <td>20.00</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[S146633506]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>obsr1896095</td>\n",
       "      <td>[{'Sequence': 1, 'Latitude': 37.2771433, 'Long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62392</th>\n",
       "      <td>F</td>\n",
       "      <td>kenyabirdmap@naturekenya.org</td>\n",
       "      <td>3720c0950_r433404_20240529</td>\n",
       "      <td>2024-05-29</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>16:11</td>\n",
       "      <td>3720c0950</td>\n",
       "      <td>22829</td>\n",
       "      <td>5.93</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[S178139251, S178166960, S178246101, S178605942]</td>\n",
       "      <td>5.40</td>\n",
       "      <td>obsr433404</td>\n",
       "      <td>[{'Sequence': 1, 'Latitude': 37.2788336, 'Long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62393</th>\n",
       "      <td>F</td>\n",
       "      <td>kenyabirdmap@naturekenya.org</td>\n",
       "      <td>3720c0950_r490904_20200302</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>07:30</td>\n",
       "      <td>3720c0950</td>\n",
       "      <td>22829</td>\n",
       "      <td>20.00</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[S65389557]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>obsr490904</td>\n",
       "      <td>[{'Sequence': 1, 'Latitude': 37.2771433, 'Long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62394</th>\n",
       "      <td>F</td>\n",
       "      <td>kenyabirdmap@naturekenya.org</td>\n",
       "      <td>3720c0950_r536040_20200302</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>07:30</td>\n",
       "      <td>3720c0950</td>\n",
       "      <td>22829</td>\n",
       "      <td>20.00</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[S65387334]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>obsr536040</td>\n",
       "      <td>[{'Sequence': 1, 'Latitude': 37.2771433, 'Long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62395</th>\n",
       "      <td>F</td>\n",
       "      <td>kenyabirdmap@naturekenya.org</td>\n",
       "      <td>4650_3740_r293179_20220127</td>\n",
       "      <td>2022-01-27</td>\n",
       "      <td>2022-01-27</td>\n",
       "      <td>10:37</td>\n",
       "      <td>4650_3740</td>\n",
       "      <td>22829</td>\n",
       "      <td>6.00</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[S101822882]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>obsr293179</td>\n",
       "      <td>[{'Sequence': 1, 'Latitude': -46.9072497, 'Lon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62396 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Protocol                 ObserverEmail                       CardNo  \\\n",
       "0            F  kenyabirdmap@naturekenya.org   0000_0920_r431479_20220810   \n",
       "1            F  kenyabirdmap@naturekenya.org   0000_0920_r431479_20240218   \n",
       "2            F  kenyabirdmap@naturekenya.org   0000_1135_r344577_19970722   \n",
       "3            F  kenyabirdmap@naturekenya.org   0000_1140_r107968_19960708   \n",
       "4            F  kenyabirdmap@naturekenya.org   0000_1140_r167174_19960708   \n",
       "...        ...                           ...                          ...   \n",
       "62391        F  kenyabirdmap@naturekenya.org  3720c0950_r1896095_20200302   \n",
       "62392        F  kenyabirdmap@naturekenya.org   3720c0950_r433404_20240529   \n",
       "62393        F  kenyabirdmap@naturekenya.org   3720c0950_r490904_20200302   \n",
       "62394        F  kenyabirdmap@naturekenya.org   3720c0950_r536040_20200302   \n",
       "62395        F  kenyabirdmap@naturekenya.org   4650_3740_r293179_20220127   \n",
       "\n",
       "        StartDate     EndDate StartTime     Pentad ObserverNo  TotalHours  \\\n",
       "0      2022-08-10  2022-08-10     11:55  0000_0920      22829        2.68   \n",
       "1      2024-02-18  2024-02-20     12:20  0000_0920      22829        3.55   \n",
       "2      1997-07-22  1997-07-22     11:00  0000_1135      22829        2.00   \n",
       "3      1996-07-08  1996-07-08     16:30  0000_1140      22829        3.00   \n",
       "4      1996-07-08  1996-07-08     16:30  0000_1140      22829        3.00   \n",
       "...           ...         ...       ...        ...        ...         ...   \n",
       "62391  2020-03-02  2020-03-02     07:30  3720c0950      22829       20.00   \n",
       "62392  2024-05-29  2024-06-01     16:11  3720c0950      22829        5.93   \n",
       "62393  2020-03-02  2020-03-02     07:30  3720c0950      22829       20.00   \n",
       "62394  2020-03-02  2020-03-02     07:30  3720c0950      22829       20.00   \n",
       "62395  2022-01-27  2022-01-27     10:37  4650_3740      22829        6.00   \n",
       "\n",
       "      Hour1  ... Hour8 Hour9 Hour10 TotalSpp InclNight AllHabitats  \\\n",
       "0            ...                          19         0           0   \n",
       "1            ...                          35         0           0   \n",
       "2            ...                           5         0           0   \n",
       "3            ...                          15         0           0   \n",
       "4            ...                          15         0           0   \n",
       "...     ...  ...   ...   ...    ...      ...       ...         ...   \n",
       "62391        ...                           3         0           0   \n",
       "62392        ...                          14         0           0   \n",
       "62393        ...                           3         0           0   \n",
       "62394        ...                           3         0           0   \n",
       "62395        ...                          23         0           0   \n",
       "\n",
       "                                              Checklists TotalDistance  \\\n",
       "0                               [S116860554, S116861241]          2.60   \n",
       "1      [S162608678, S162609512, S162830782, S16283088...          3.50   \n",
       "2                                            [S13388886]          1.00   \n",
       "3                                             [S7529043]          1.61   \n",
       "4                                             [S7529228]          1.61   \n",
       "...                                                  ...           ...   \n",
       "62391                                       [S146633506]          0.00   \n",
       "62392   [S178139251, S178166960, S178246101, S178605942]          5.40   \n",
       "62393                                        [S65389557]          0.00   \n",
       "62394                                        [S65387334]          0.00   \n",
       "62395                                       [S101822882]          0.00   \n",
       "\n",
       "      ObserverNoEbird                                            records  \n",
       "0          obsr431479  [{'Sequence': 1, 'Latitude': -0.0392179, 'Long...  \n",
       "1          obsr431479  [{'Sequence': 1, 'Latitude': -0.0392179, 'Long...  \n",
       "2          obsr344577  [{'Sequence': 1, 'Latitude': -0.0686645, 'Long...  \n",
       "3          obsr107968  [{'Sequence': 1, 'Latitude': -0.0700264, 'Long...  \n",
       "4          obsr167174  [{'Sequence': 1, 'Latitude': -0.0700264, 'Long...  \n",
       "...               ...                                                ...  \n",
       "62391     obsr1896095  [{'Sequence': 1, 'Latitude': 37.2771433, 'Long...  \n",
       "62392      obsr433404  [{'Sequence': 1, 'Latitude': 37.2788336, 'Long...  \n",
       "62393      obsr490904  [{'Sequence': 1, 'Latitude': 37.2771433, 'Long...  \n",
       "62394      obsr536040  [{'Sequence': 1, 'Latitude': 37.2771433, 'Long...  \n",
       "62395      obsr293179  [{'Sequence': 1, 'Latitude': -46.9072497, 'Lon...  \n",
       "\n",
       "[62396 rows x 26 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the card information by checklist and species into an export card dataframe\n",
    "card_exp = pd.merge(\n",
    "    card_chk,\n",
    "    card_sp,\n",
    "    on=\"CARD\",\n",
    ")\n",
    "\n",
    "# Set some default values\n",
    "card_exp[\"Protocol\"] = \"F\"\n",
    "card_exp[\"ObserverEmail\"] = \"kenyabirdmap@naturekenya.org\"\n",
    "card_exp[\"ObserverNo\"] = \"22829\"\n",
    "\n",
    "card_exp[\"Hour1\"] = \"\"\n",
    "card_exp[\"Hour2\"] = \"\"\n",
    "card_exp[\"Hour3\"] = \"\"\n",
    "card_exp[\"Hour4\"] = \"\"\n",
    "card_exp[\"Hour5\"] = \"\"\n",
    "card_exp[\"Hour6\"] = \"\"\n",
    "card_exp[\"Hour7\"] = \"\"\n",
    "card_exp[\"Hour8\"] = \"\"\n",
    "card_exp[\"Hour9\"] = \"\"\n",
    "card_exp[\"Hour10\"] = \"\"\n",
    "card_exp[\"InclNight\"] = \"0\"\n",
    "card_exp[\"AllHabitats\"] = \"0\"\n",
    "\n",
    "card_exp[\"TotalHours\"] = round(card_exp[\"DURATION MINUTES_sum\"] / 60, 2)\n",
    "card_exp[\"TotalDistance\"] = round(card_exp[\"EFFORT DISTANCE KM_sum\"], 2)\n",
    "card_exp[\"TotalSpp\"] = card_exp[\"ADU\"].apply(lambda x: len(x))\n",
    "card_exp[\"StartDate\"] = card_exp[\"OBSERVATION DATETIME_min\"].dt.date.apply(str)\n",
    "card_exp[\"EndDate\"] = card_exp[\"OBSERVATION DATETIME_max\"].dt.date.apply(str)\n",
    "card_exp[\"StartTime\"] = card_exp[\"OBSERVATION DATETIME_min\"].dt.strftime(\"%H:%M\")\n",
    "\n",
    "\n",
    "# Function that generate species record to be used for each species of each card\n",
    "def create_records(\n",
    "    ADU, SEQ, LATITUDE, LONGITUDE, OBSERVATION_DATETIME, EFFORT_DISTANCE_KM, CARD\n",
    "):\n",
    "    return [\n",
    "        {\n",
    "            \"Sequence\": SEQ,\n",
    "            \"Latitude\": LATITUDE,\n",
    "            \"Longitude\": LONGITUDE,\n",
    "            \"Altitude\": \"\",\n",
    "            \"CardNo\": CARD,\n",
    "            \"Spp\": ADU,\n",
    "            \"Accuracy\": EFFORT_DISTANCE_KM * 1000,\n",
    "            \"SightingTime\": OBSERVATION_DATETIME,\n",
    "        }\n",
    "        for ADU, SEQ, LATITUDE, LONGITUDE, OBSERVATION_DATETIME, EFFORT_DISTANCE_KM in zip(\n",
    "            ADU, SEQ, LATITUDE, LONGITUDE, OBSERVATION_DATETIME, EFFORT_DISTANCE_KM\n",
    "        )\n",
    "    ]\n",
    "\n",
    "\n",
    "# Apply the function\n",
    "card_exp[\"records\"] = card_exp.apply(\n",
    "    lambda row: create_records(\n",
    "        row[\"ADU\"],\n",
    "        row[\"SEQ\"],\n",
    "        row[\"LATITUDE\"],\n",
    "        row[\"LONGITUDE\"],\n",
    "        row[\"OBSERVATION DATETIME\"],\n",
    "        row[\"EFFORT DISTANCE KM\"],\n",
    "        row[\"CARD\"],\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Rename to match ABAP server input\n",
    "card_exp = card_exp.rename(\n",
    "    columns={\n",
    "        \"CARD\": \"CardNo\",\n",
    "        \"PENTAD\": \"Pentad\",\n",
    "        \"SAMPLING EVENT IDENTIFIER\": \"Checklists\",\n",
    "        \"OBSERVER ID\": \"ObserverNoEbird\",\n",
    "        \"SAMPLING EVENT IDENTIFIER_list\": \"Checklists\",\n",
    "    }\n",
    ")\n",
    "\n",
    "card_exp = card_exp.reindex(\n",
    "    columns=[\n",
    "        \"Protocol\",\n",
    "        \"ObserverEmail\",\n",
    "        \"CardNo\",\n",
    "        \"StartDate\",\n",
    "        \"EndDate\",\n",
    "        \"StartTime\",\n",
    "        \"Pentad\",\n",
    "        \"ObserverNo\",\n",
    "        \"TotalHours\",\n",
    "        \"Hour1\",\n",
    "        \"Hour2\",\n",
    "        \"Hour3\",\n",
    "        \"Hour4\",\n",
    "        \"Hour5\",\n",
    "        \"Hour6\",\n",
    "        \"Hour7\",\n",
    "        \"Hour8\",\n",
    "        \"Hour9\",\n",
    "        \"Hour10\",\n",
    "        \"TotalSpp\",\n",
    "        \"InclNight\",\n",
    "        \"AllHabitats\",\n",
    "        \"Checklists\",\n",
    "        \"TotalDistance\",\n",
    "        \"ObserverNoEbird\",\n",
    "        \"records\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "card_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = card_exp.to_json(orient=\"records\", indent=2)\n",
    "with open(\n",
    "    f\"../export/ebd_AFR_rel{month}-{year}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    f.write(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export in better format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_chk.to_csv(\n",
    "    f\"../export/ebd_AFR_rel{month}-{year}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}_cards.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ebd_f_u[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCARD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADU\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSEQ\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../export/ebd_AFR_rel\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_records.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:3964\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3953\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3955\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3956\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3957\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3961\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3962\u001b[0m )\n\u001b[0;32m-> 3964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[1;32m   3965\u001b[0m     path_or_buf,\n\u001b[1;32m   3966\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   3967\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[1;32m   3968\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   3969\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m   3970\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m   3971\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[1;32m   3972\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   3973\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[1;32m   3974\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m   3975\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m   3976\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[1;32m   3977\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[1;32m   3978\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[1;32m   3979\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[1;32m   3980\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m   3981\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/csvs.py:270\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/csvs.py:275\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_body()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_chunk(start_i, end_i)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/csvs.py:320\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    317\u001b[0m slicer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(start_i, end_i)\n\u001b[1;32m    318\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc[slicer]\n\u001b[0;32m--> 320\u001b[0m res \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_get_values_for_csv(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[1;32m    321\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(res\u001b[38;5;241m.\u001b[39m_iter_column_arrays())\n\u001b[1;32m    323\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_get_values_for_csv(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:1399\u001b[0m, in \u001b[0;36mDataFrame._get_values_for_csv\u001b[0;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_values_for_csv\u001b[39m(\n\u001b[1;32m   1390\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1391\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1397\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1398\u001b[0m     \u001b[38;5;66;03m# helper used by to_csv\u001b[39;00m\n\u001b[0;32m-> 1399\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mget_values_for_csv(\n\u001b[1;32m   1400\u001b[0m         float_format\u001b[38;5;241m=\u001b[39mfloat_format,\n\u001b[1;32m   1401\u001b[0m         date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[1;32m   1402\u001b[0m         decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   1403\u001b[0m         na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   1404\u001b[0m         quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[1;32m   1405\u001b[0m     )\n\u001b[1;32m   1406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(mgr, axes\u001b[38;5;241m=\u001b[39mmgr\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:466\u001b[0m, in \u001b[0;36mBaseBlockManager.get_values_for_csv\u001b[0;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_values_for_csv\u001b[39m(\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, float_format, date_format, decimal, na_rep: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, quoting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    461\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m    462\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;124;03m    Convert values to native types (strings / python objects) that are used\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;124;03m    in formatting (repr / csv).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    467\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_values_for_csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    468\u001b[0m         na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m    469\u001b[0m         quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[1;32m    470\u001b[0m         float_format\u001b[38;5;241m=\u001b[39mfloat_format,\n\u001b[1;32m    471\u001b[0m         date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[1;32m    472\u001b[0m         decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m    473\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/blocks.py:780\u001b[0m, in \u001b[0;36mBlock.get_values_for_csv\u001b[0;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_values_for_csv\u001b[39m(\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, float_format, date_format, decimal, na_rep: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, quoting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    778\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Block:\n\u001b[1;32m    779\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"convert to our native types format\"\"\"\u001b[39;00m\n\u001b[0;32m--> 780\u001b[0m     result \u001b[38;5;241m=\u001b[39m get_values_for_csv(\n\u001b[1;32m    781\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m    782\u001b[0m         na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m    783\u001b[0m         quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[1;32m    784\u001b[0m         float_format\u001b[38;5;241m=\u001b[39mfloat_format,\n\u001b[1;32m    785\u001b[0m         date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[1;32m    786\u001b[0m         decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m    787\u001b[0m     )\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7873\u001b[0m, in \u001b[0;36mget_values_for_csv\u001b[0;34m(values, date_format, na_rep, quoting, float_format, decimal)\u001b[0m\n\u001b[1;32m   7871\u001b[0m         values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<U\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitemsize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 7873\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(values, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7875\u001b[0m values[mask] \u001b[38;5;241m=\u001b[39m na_rep\n\u001b[1;32m   7876\u001b[0m values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ebd_f_u[[\"CARD\", \"ADU\", \"SEQ\"]].to_csv(\n",
    "    f\"../export/ebd_AFR_rel{month}-{year}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}_records.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
