{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to compute ABAP card from eBird data\n",
    "\n",
    "The aims of this code is to produce a dataset of ABAP full protocol card equivalent from the eBird EBD dataset.\n",
    "\n",
    "## Overview rational of the approach\n",
    "\n",
    "A card is uniquely defined by three elements: pentad*code, user_id, and date of the first day of the 5 days. We therefore use the `card_id = {pentad}*{observer}\\_{date}`. From these three variables, it is possible to find all checklists that belong to it.\n",
    "\n",
    "The aim here is to build a list of **valid** cards for which will then be used to find the `checklist_id` that belongs to each valid card and then finally compute the card info from the list of checklists.\n",
    "\n",
    "Pentad: we need to assign for each checklist its pentad and check that the distance traveled is within the boundary of the pentad.\n",
    "User_id is quite straightforward to build.\n",
    "Date: much more challenging. See below for details.\n",
    "\n",
    "General steps:\n",
    "\n",
    "1. Construct the list of valid cards\n",
    "   1. Group raw EBD data to checklist level information (merge shared checklist)\n",
    "   2. Filter checklists which could make a valid card\n",
    "      1. Keep only complete checklists\n",
    "      2. Keep only checklists with `Historical`, `Stationary`, `Traveling`, `Incidental` protocol\n",
    "      3. Keep only checklists within the pentad, that is,\n",
    "         1. Exclude checklists with `historical` protocol that don't have a distance.\n",
    "         2. Exclude checklists with distance greater than the distance from center of checklist to closest pentad limit (accept some overlap with a correction factor).\n",
    "      4. Keep only checklists with duration greated than 0.\n",
    "   3. Group checklists by date (named `checkday` later on)\n",
    "   4. Group checklists into pentad_observer group so that we only have to loop through the date to find valid card\n",
    "   5. Preliminary filter to eliminate all pentad_observer for which the sum over the entire period does not lead to 2h\n",
    "   6. For each remaining pentad_observer, apply the function `checkday_pentad_observer()`, which,\n",
    "      1. Compute the temporal distance between all checkday and check if they are within 5 days.\n",
    "      2. Loop through all checkday,\n",
    "         1. Compute the total duration of all checkdays within temporal distance\n",
    "            1. If valid, create the card_id and apply it to all checkday. Iterate to the first next checkday that was not within temporal distance\n",
    "            2. If invalid, iterate to the next checkday\n",
    "2. Create the card data\n",
    "   1. For each valid card, aggregate all checklists which are (1) within pentad, (2) same observer and (3) day within the 5 day period. This include more checklists than used to construct the list of valid cards\n",
    "3. Add species level information to cards\n",
    "   1. Add sequence information based on first occurance on checklist.\n",
    "4. Export in JSON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General set-up\n",
    "\n",
    "### Load library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "import requests\n",
    "import tarfile\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "# Add the parent directory to the system path so the notebook can find the eBird2ABAP package\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "# Now import the necessary functions from utils.py\n",
    "from eBird2ABAP.utils import latlng2pentad, pentad2latlng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the latest EBD AFRICA data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code doesn't work as you need to sign in into to get access to the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_EBD(year=None, month=None):\n",
    "    if year == None | month == None:\n",
    "        # Calculate previous month and year\n",
    "        today = datetime.date.today()\n",
    "        last_month = today.replace(day=1) - datetime.timedelta(days=1)\n",
    "        if year == None:\n",
    "            year = last_month.strftime(\"%Y\")\n",
    "        if month == None:\n",
    "            month = last_month.strftime(\"%b\")\n",
    "\n",
    "    # Construct URL and filename\n",
    "    url = f\"https://ebird.org/data/download?p=prepackaged/ebd_AFR_rel{month}-{year}.tar\"\n",
    "    filename = os.path.basename(url)\n",
    "    filepath = os.path.join(\"../data/eBird/\", filename)\n",
    "\n",
    "    # with open(filepath, \"wb\") as f:\n",
    "    #     f.write(requests.get(url).content)\n",
    "\n",
    "    # with tarfile.open(filepath, \"r\") as tar:\n",
    "    #     tar.extractall(f\"../data/eBird/ebd_AFR_rel{month}-{year}/\")\n",
    "\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_EBD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the EBD file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_EBD(file):\n",
    "    ebd0 = pd.read_csv(\n",
    "        file,\n",
    "        delimiter=\"\\t\",\n",
    "        usecols=[\n",
    "            \"SAMPLING EVENT IDENTIFIER\",\n",
    "            \"SCIENTIFIC NAME\",\n",
    "            \"TAXON CONCEPT ID\",\n",
    "            \"CATEGORY\",\n",
    "            \"LATITUDE\",\n",
    "            \"LONGITUDE\",\n",
    "            \"OBSERVATION DATE\",\n",
    "            \"TIME OBSERVATIONS STARTED\",\n",
    "            \"PROTOCOL TYPE\",\n",
    "            \"DURATION MINUTES\",\n",
    "            \"EFFORT DISTANCE KM\",\n",
    "            \"ALL SPECIES REPORTED\",\n",
    "            \"OBSERVER ID\",\n",
    "        ],\n",
    "        parse_dates=[\"OBSERVATION DATE\"],\n",
    "    )\n",
    "\n",
    "    ebd = ebd0\n",
    "\n",
    "    # Create OBSERVATIONDATETIME by combining date and time\n",
    "    tmp = ebd[\"TIME OBSERVATIONS STARTED\"].fillna(\"00:00:00\")\n",
    "    ebd[\"OBSERVATION DATETIME\"] = pd.to_datetime(\n",
    "        ebd[\"OBSERVATION DATE\"].dt.strftime(\"%Y-%m-%d\") + \" \" + tmp,\n",
    "        format=\"%Y-%m-%d %H:%M:%S\",\n",
    "    )\n",
    "\n",
    "    # Sort by date: Important to have for filtering duplicate card-adu and needed for sequence\n",
    "    ebd.sort_values(by=\"OBSERVATION DATETIME\", inplace=True)\n",
    "\n",
    "    # Keep only species category\n",
    "    # ebd0[[\"COMMONNAME\", \"SCIENTIFIC NAME\", \"CATEGORY\"]].drop_duplicates().to_csv(\"species_list_ebird.csv\", index=False)\n",
    "\n",
    "    # Keep some spuh which can be matched to an ADU\n",
    "    # spuh_keep = pd.read_csv(\"data/spuh_keep.csv\", dtype=str)\n",
    "    # ebd0 = ebd0[(~ebd0[\"CATEGORY\"].isin([\"spuh\", \"slash\"])) | ebd0[\"SCIENTIFIC NAME\"].isin(spuh_keep[\"Clements--scientific_name\"])]\n",
    "\n",
    "    return ebd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2024\"\n",
    "month = \"Jul\"\n",
    "\n",
    "# file = \"../data/eBird/ebd_AFR_rel{month}-{year}/ebd_AFR_rel{month}-{year}.txt.gz\"\n",
    "file = f\"../data/eBird/ebd_AFR_rel{month}-{year}/ebd_AFR_rel{month}-{year}.txt.gz\"\n",
    "# file = \"../data/eBird/ebd_AFR_relJul-2024/ebd_AFR_relJul-2024.txt.gz\"\n",
    "\n",
    "\n",
    "# For country specific EBD file, you can use:\n",
    "# cntr = \"KE\"\n",
    "# file = \"../data/eBird/chk_{cntr}_relAug-2022/ebd_{cntr}_relAug-2022.txt\"\n",
    "\n",
    "ebd = read_EBD(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TAXON CONCEPT ID</th>\n",
       "      <th>SCIENTIFIC NAME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>OBSERVATION DATE</th>\n",
       "      <th>TIME OBSERVATIONS STARTED</th>\n",
       "      <th>OBSERVER ID</th>\n",
       "      <th>SAMPLING EVENT IDENTIFIER</th>\n",
       "      <th>PROTOCOL TYPE</th>\n",
       "      <th>DURATION MINUTES</th>\n",
       "      <th>EFFORT DISTANCE KM</th>\n",
       "      <th>ALL SPECIES REPORTED</th>\n",
       "      <th>OBSERVATION DATETIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382043</th>\n",
       "      <td>species</td>\n",
       "      <td>avibase-7EE005BD</td>\n",
       "      <td>Phaethon aethereus</td>\n",
       "      <td>16.012736</td>\n",
       "      <td>-23.852151</td>\n",
       "      <td>1832-01-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>obsr939641</td>\n",
       "      <td>S126285649</td>\n",
       "      <td>Historical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1832-01-23 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741355</th>\n",
       "      <td>species</td>\n",
       "      <td>avibase-E6536E4E</td>\n",
       "      <td>Larus dominicanus</td>\n",
       "      <td>-24.639209</td>\n",
       "      <td>14.530987</td>\n",
       "      <td>1845-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>obsr4458114</td>\n",
       "      <td>S151363283</td>\n",
       "      <td>Historical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1845-10-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040394</th>\n",
       "      <td>species</td>\n",
       "      <td>avibase-9B183BDD</td>\n",
       "      <td>Spheniscus demersus</td>\n",
       "      <td>-24.639209</td>\n",
       "      <td>14.530987</td>\n",
       "      <td>1845-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>obsr4458114</td>\n",
       "      <td>S151363283</td>\n",
       "      <td>Historical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1845-10-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334069</th>\n",
       "      <td>species</td>\n",
       "      <td>avibase-AE61BF48</td>\n",
       "      <td>Phalacrocorax capensis</td>\n",
       "      <td>-24.639209</td>\n",
       "      <td>14.530987</td>\n",
       "      <td>1845-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>obsr4458114</td>\n",
       "      <td>S151363283</td>\n",
       "      <td>Historical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1845-10-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302032</th>\n",
       "      <td>species</td>\n",
       "      <td>avibase-775E93D7</td>\n",
       "      <td>Morus capensis</td>\n",
       "      <td>-24.639209</td>\n",
       "      <td>14.530987</td>\n",
       "      <td>1845-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>obsr4458114</td>\n",
       "      <td>S151363283</td>\n",
       "      <td>Historical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1845-10-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20941724</th>\n",
       "      <td>species</td>\n",
       "      <td>avibase-79A45DAF</td>\n",
       "      <td>Andropadus importunus</td>\n",
       "      <td>-4.418870</td>\n",
       "      <td>39.511232</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>21:08:00</td>\n",
       "      <td>obsr640800</td>\n",
       "      <td>S189700405</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-07-31 21:08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20032922</th>\n",
       "      <td>species</td>\n",
       "      <td>avibase-49D9148A</td>\n",
       "      <td>Ardea alba</td>\n",
       "      <td>-4.418870</td>\n",
       "      <td>39.511232</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>21:08:00</td>\n",
       "      <td>obsr640800</td>\n",
       "      <td>S189700405</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-07-31 21:08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19512682</th>\n",
       "      <td>species</td>\n",
       "      <td>avibase-550DE745</td>\n",
       "      <td>Threskiornis aethiopicus</td>\n",
       "      <td>-4.418870</td>\n",
       "      <td>39.511232</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>21:08:00</td>\n",
       "      <td>obsr640800</td>\n",
       "      <td>S189700405</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-07-31 21:08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20289131</th>\n",
       "      <td>species</td>\n",
       "      <td>avibase-6429024D</td>\n",
       "      <td>Ardea cinerea</td>\n",
       "      <td>-4.418870</td>\n",
       "      <td>39.511232</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>21:08:00</td>\n",
       "      <td>obsr640800</td>\n",
       "      <td>S189700405</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-07-31 21:08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21182982</th>\n",
       "      <td>species</td>\n",
       "      <td>avibase-2E6575A8</td>\n",
       "      <td>Strix woodfordii</td>\n",
       "      <td>0.304880</td>\n",
       "      <td>32.608814</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>21:10:00</td>\n",
       "      <td>obsr1377183</td>\n",
       "      <td>S189699949</td>\n",
       "      <td>Incidental</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-31 21:10:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21190167 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CATEGORY  TAXON CONCEPT ID           SCIENTIFIC NAME   LATITUDE  \\\n",
       "382043    species  avibase-7EE005BD        Phaethon aethereus  16.012736   \n",
       "741355    species  avibase-E6536E4E         Larus dominicanus -24.639209   \n",
       "1040394   species  avibase-9B183BDD       Spheniscus demersus -24.639209   \n",
       "334069    species  avibase-AE61BF48    Phalacrocorax capensis -24.639209   \n",
       "302032    species  avibase-775E93D7            Morus capensis -24.639209   \n",
       "...           ...               ...                       ...        ...   \n",
       "20941724  species  avibase-79A45DAF     Andropadus importunus  -4.418870   \n",
       "20032922  species  avibase-49D9148A                Ardea alba  -4.418870   \n",
       "19512682  species  avibase-550DE745  Threskiornis aethiopicus  -4.418870   \n",
       "20289131  species  avibase-6429024D             Ardea cinerea  -4.418870   \n",
       "21182982  species  avibase-2E6575A8          Strix woodfordii   0.304880   \n",
       "\n",
       "          LONGITUDE OBSERVATION DATE TIME OBSERVATIONS STARTED  OBSERVER ID  \\\n",
       "382043   -23.852151       1832-01-23                       NaN   obsr939641   \n",
       "741355    14.530987       1845-10-01                       NaN  obsr4458114   \n",
       "1040394   14.530987       1845-10-01                       NaN  obsr4458114   \n",
       "334069    14.530987       1845-10-01                       NaN  obsr4458114   \n",
       "302032    14.530987       1845-10-01                       NaN  obsr4458114   \n",
       "...             ...              ...                       ...          ...   \n",
       "20941724  39.511232       2024-07-31                  21:08:00   obsr640800   \n",
       "20032922  39.511232       2024-07-31                  21:08:00   obsr640800   \n",
       "19512682  39.511232       2024-07-31                  21:08:00   obsr640800   \n",
       "20289131  39.511232       2024-07-31                  21:08:00   obsr640800   \n",
       "21182982  32.608814       2024-07-31                  21:10:00  obsr1377183   \n",
       "\n",
       "         SAMPLING EVENT IDENTIFIER PROTOCOL TYPE  DURATION MINUTES  \\\n",
       "382043                  S126285649    Historical               NaN   \n",
       "741355                  S151363283    Historical               NaN   \n",
       "1040394                 S151363283    Historical               NaN   \n",
       "334069                  S151363283    Historical               NaN   \n",
       "302032                  S151363283    Historical               NaN   \n",
       "...                            ...           ...               ...   \n",
       "20941724                S189700405    Stationary              60.0   \n",
       "20032922                S189700405    Stationary              60.0   \n",
       "19512682                S189700405    Stationary              60.0   \n",
       "20289131                S189700405    Stationary              60.0   \n",
       "21182982                S189699949    Incidental               NaN   \n",
       "\n",
       "          EFFORT DISTANCE KM  ALL SPECIES REPORTED OBSERVATION DATETIME  \n",
       "382043                   NaN                     0  1832-01-23 00:00:00  \n",
       "741355                   NaN                     0  1845-10-01 00:00:00  \n",
       "1040394                  NaN                     0  1845-10-01 00:00:00  \n",
       "334069                   NaN                     0  1845-10-01 00:00:00  \n",
       "302032                   NaN                     0  1845-10-01 00:00:00  \n",
       "...                      ...                   ...                  ...  \n",
       "20941724                 NaN                     1  2024-07-31 21:08:00  \n",
       "20032922                 NaN                     1  2024-07-31 21:08:00  \n",
       "19512682                 NaN                     1  2024-07-31 21:08:00  \n",
       "20289131                 NaN                     1  2024-07-31 21:08:00  \n",
       "21182982                 NaN                     0  2024-07-31 21:10:00  \n",
       "\n",
       "[21190167 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add species taxonomy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ADU(\n",
    "    ebd, file=\"../data/species_list/matched_species.csv\", return_unmatched=False\n",
    "):\n",
    "    # Read matched_species data. See species_match.ipynb\n",
    "    matched_species = pd.read_csv(file)\n",
    "\n",
    "    ebd = pd.merge(\n",
    "        ebd,  # .loc[:,['OBSERVER ID', 'PENTAD', \"SAMPLING EVENT IDENTIFIER\", \"OBSERVATION DATE\"]],\n",
    "        matched_species[[\"TAXON CONCEPT ID\", \"ADU\"]].drop_duplicates(\n",
    "            subset=\"TAXON CONCEPT ID\"\n",
    "        ),\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    if return_unmatched:\n",
    "        unmatched = (\n",
    "            ebd[ebd[\"ADU\"].isna()][[\"SCIENTIFIC NAME\"]]\n",
    "            .value_counts()\n",
    "            .sort_values(ascending=0)\n",
    "        )\n",
    "        print(\n",
    "            f\"We still have {len(unmatched)} unmatched taxons, corresponding to {round(sum(unmatched)/len(ebd)*100)}% of our data\"\n",
    "        )\n",
    "        return unmatched\n",
    "    else:\n",
    "        ebd[\"ADU\"] = ebd[\"ADU\"].fillna(0).astype(int)\n",
    "        return ebd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We still have 1260 unmatched taxons, corresponding to 7% of our data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SCIENTIFIC NAME        \n",
       "Icthyophaga vocifer        90635\n",
       "Spermestes cucullata       82830\n",
       "Columba livia              62539\n",
       "Zapornia flavirostra       51197\n",
       "Lanius melanoleucus        34528\n",
       "                           ...  \n",
       "Chamaea fasciata               1\n",
       "Chalcoparia singalensis        1\n",
       "Chaetura pelagica              1\n",
       "Turnix velox                   1\n",
       "Sicalis luteola                1\n",
       "Name: count, Length: 1260, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_ADU(ebd, return_unmatched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebd = add_ADU(ebd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# data: 21190167\n",
      "# Checklists: 1262874\n",
      "# Species: 3127\n"
     ]
    }
   ],
   "source": [
    "print(f\"# data: {len(ebd)}\")\n",
    "print(f\"# Checklists: {len(ebd['SAMPLING EVENT IDENTIFIER'].unique())}\")\n",
    "print(f\"# Species: {len(ebd['SCIENTIFIC NAME'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build checklist dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebd2chk(ebd):\n",
    "    chk = ebd[\n",
    "        [\n",
    "            \"SAMPLING EVENT IDENTIFIER\",\n",
    "            \"LATITUDE\",\n",
    "            \"LONGITUDE\",\n",
    "            \"OBSERVATION DATE\",\n",
    "            \"OBSERVATION DATETIME\",\n",
    "            \"PROTOCOL TYPE\",\n",
    "            \"DURATION MINUTES\",\n",
    "            \"EFFORT DISTANCE KM\",\n",
    "            \"ALL SPECIES REPORTED\",\n",
    "            \"OBSERVER ID\",\n",
    "        ]\n",
    "    ].drop_duplicates()\n",
    "\n",
    "    # Sort by date\n",
    "    chk.sort_values(by=\"OBSERVATION DATETIME\", inplace=True)\n",
    "\n",
    "    # For some shared checklist some variable are different for the same sampling event.\n",
    "    # chk[chk[\"SAMPLING EVENT IDENTIFIER\"].duplicated(keep=False)].sort_values(by=\"SAMPLING EVENT IDENTIFIER\")\n",
    "    # ebd0[ebd0[\"SAMPLING EVENT IDENTIFIER\"] == \"S97700871\"]\n",
    "    chk = chk.drop_duplicates(\"SAMPLING EVENT IDENTIFIER\").reset_index(drop=True)\n",
    "    len(chk)\n",
    "\n",
    "    # Filter protocol\n",
    "    chk[\"KEEP PROTOCOL\"] = chk[\"PROTOCOL TYPE\"].isin(\n",
    "        [\"Historical\", \"Incidental\", \"Stationary\", \"Traveling\"]\n",
    "    )\n",
    "\n",
    "    # Pentad\n",
    "    # Assign the pentad to all checklists based on their location\n",
    "    chk[\"PENTAD\"] = latlng2pentad(chk[\"LATITUDE\"], chk[\"LONGITUDE\"])\n",
    "\n",
    "    # Retrieve the lat, lon center of the assigned pentad\n",
    "    lat, lon = pentad2latlng(chk[\"PENTAD\"])\n",
    "\n",
    "    # Convert effort distance of the checklisst into degree lat-lon\n",
    "    effort_distance_lat = 180 / np.pi / 6371 * chk[\"EFFORT DISTANCE KM\"]\n",
    "    effort_distance_lon = (\n",
    "        180\n",
    "        / np.pi\n",
    "        / 6371\n",
    "        / np.cos(np.radians(chk[\"LATITUDE\"]))\n",
    "        * chk[\"EFFORT DISTANCE KM\"]\n",
    "    )\n",
    "\n",
    "    # Compute the distance from the center of the pentad (lat,lon) to the max distance possible if the observer traveled in the worst possible direction (i.e., to the closest eadge of the pentad)\n",
    "    # We relax a little bit the assumption of moving on the straight line to the edge of the pentad by applying a correction factor\n",
    "    corr_straight_line = 0.8\n",
    "    dist_lat = np.abs(lat - chk[\"LATITUDE\"]) + effort_distance_lat * corr_straight_line\n",
    "    dist_lon = np.abs(lon - chk[\"LONGITUDE\"]) + effort_distance_lon * corr_straight_line\n",
    "\n",
    "    # The maximum distance allowed for the checklist to be considered valid is half of a pentad resolution (5/60°)\n",
    "    # We accept that the checklist might have traveled a bit more that this distance\n",
    "    corr_overlap = 1.2  # allow for a 20% overlap\n",
    "    max_dist = (5 / 60 / 2) * corr_overlap\n",
    "\n",
    "    chk[\"KEEP PENTAD\"] = (dist_lat < max_dist) & (dist_lon < max_dist)\n",
    "\n",
    "    # Filter historical checklists which have no distance\n",
    "    chk.loc[\n",
    "        (chk[\"PROTOCOL TYPE\"] == \"Historical\") & chk[\"EFFORT DISTANCE KM\"].isna(),\n",
    "        \"KEEP PENTAD\",\n",
    "    ] = False\n",
    "\n",
    "    # Filter historical checklists which have no distance\n",
    "    chk.loc[\n",
    "        chk[\"EFFORT DISTANCE KM\"].isna(),\n",
    "        \"KEEP PENTAD\",\n",
    "    ] = True\n",
    "\n",
    "    chk.loc[\n",
    "        (chk[\"PROTOCOL TYPE\"] == \"Historical\") & chk[\"EFFORT DISTANCE KM\"].isna(),\n",
    "        \"KEEP PENTAD\",\n",
    "    ] = False\n",
    "\n",
    "    return chk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk = ebd2chk(ebd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all possible valid card\n",
    "\n",
    "Cards are considered to be full protocol if the sum of durations of the underlying checklists exceed 2 hours over the next rolling 5 days.\n",
    "In this section, we first indentify which checklists can create a valid full card.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkday_pentad_observer(df):\n",
    "    # To find all pentad with sufficient duration effort (i.e, a sum of 2h over 5 days period), we apply this function for each pentad_observer.\n",
    "\n",
    "    df[\"CARD\"] = \"\"\n",
    "    # Build a matrix of distance between all checklists to check if they are close to each other\n",
    "    di = np.abs(\n",
    "        df[\"OBSERVATION DATE\"].values[:, None] - df[\"OBSERVATION DATE\"].values\n",
    "    ) < pd.Timedelta(days=5)\n",
    "    # create duration array to make computation slightly faster\n",
    "    duration = df[\"DURATION MINUTES\"].to_numpy()\n",
    "    # Initie the card array with empty string\n",
    "    # card = np.array(['' for x in range(len(df))], dtype='object')\n",
    "    u = 1\n",
    "    # Loop trough the list of checklists\n",
    "    while u <= len(df):\n",
    "        # Find all neighbord\n",
    "        nb_neighbor = np.sum(di[u - 1, (u - 1) :])\n",
    "        neigh = u + np.arange(0, nb_neighbor) - 1\n",
    "        dur = duration[neigh].sum()\n",
    "        # Check that total duration is more than 2hours, if so add card code (pentad_observer_date) to card array\n",
    "        if dur >= (2 * 60):\n",
    "            df.iloc[neigh, df.columns.get_loc(\"CARD\")] = df.iloc[\n",
    "                u - 1, df.columns.get_loc(\"pentad_observer_date\")\n",
    "            ]\n",
    "        u += nb_neighbor\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chk2valid_card(chk):\n",
    "    # Find all possible valid card\n",
    "    # Cards are considered to be full protocol if the sum of durations of the underlying checklists exceed 2 hours over the next rolling 5 days.\n",
    "    # In this section, we first indentify which checklists can create a valid full card.\n",
    "\n",
    "    # Find the index of all checklists which contribute to the 2hr rule. Note that we will still use \"non-valid\" checklists later as their species still contribute to the card.\n",
    "    valid_id = (\n",
    "        chk[\"KEEP PENTAD\"]\n",
    "        & chk[\"KEEP PROTOCOL\"]\n",
    "        & (chk[\"DURATION MINUTES\"] > 0)\n",
    "        & chk[\"ALL SPECIES REPORTED\"]\n",
    "    )\n",
    "\n",
    "    # Filter for valid checklist and create in a smaller table\n",
    "    check = chk.loc[\n",
    "        valid_id, [\"PENTAD\", \"OBSERVER ID\", \"OBSERVATION DATE\", \"DURATION MINUTES\"]\n",
    "    ]\n",
    "\n",
    "    # Combine checklists made by the same observer, pentad, and day. This is an intermediate step which enables us to grid the 5 days windows more easily\n",
    "    checkday = (\n",
    "        check.groupby([\"PENTAD\", \"OBSERVER ID\", \"OBSERVATION DATE\"])\n",
    "        .agg({\"DURATION MINUTES\": \"sum\"})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Sort the checklist by date\n",
    "    checkday.sort_values(by=[\"OBSERVATION DATE\"], inplace=True)\n",
    "\n",
    "    # Create additional columns\n",
    "    checkday[\"pentad_observer\"] = checkday[\"PENTAD\"] + \"_\" + checkday[\"OBSERVER ID\"]\n",
    "    checkday[\"pentad_observer_date\"] = (\n",
    "        checkday[\"PENTAD\"]\n",
    "        + \"_\"\n",
    "        + checkday[\"OBSERVER ID\"].str[3:]\n",
    "        + \"_\"\n",
    "        + checkday[\"OBSERVATION DATE\"].dt.strftime(\"%Y%m%d\")\n",
    "    )\n",
    "\n",
    "    # Do a first filter to eliminate all pentad_observer witout sufficient total duration time. (Aim is to just reduce the computation later)\n",
    "    pentad_observer_duration = checkday.groupby([\"pentad_observer\"])[\n",
    "        \"DURATION MINUTES\"\n",
    "    ].sum()\n",
    "    pentad_observer_duration_index = pentad_observer_duration[\n",
    "        pentad_observer_duration >= 2 * 60\n",
    "    ].index\n",
    "    checkday_long = checkday[\n",
    "        checkday[\"pentad_observer\"].isin(pentad_observer_duration_index)\n",
    "    ]\n",
    "\n",
    "    # Second filter for reducing the test case\n",
    "    # pentad_observer_unique = checkday_long[\"pentad_observer\"].unique()\n",
    "    # pentad_observer_unique = pentad_observer_unique[0:1000]\n",
    "    # checkday_long = checkday_long[checkday_long[\"pentad_observer\"].isin(pentad_observer_unique)]\n",
    "\n",
    "    # Apply the function defined above for each pentad-observer at the same time (makes operation much faster)\n",
    "    checkday_long_card = (\n",
    "        checkday_long.groupby(\"pentad_observer\")\n",
    "        .apply(checkday_pentad_observer, include_groups=False)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Create the DataFrame of all valid card\n",
    "    card_valid = checkday_long_card[\n",
    "        checkday_long_card[\"CARD\"] == checkday_long_card[\"pentad_observer_date\"]\n",
    "    ][[\"PENTAD\", \"OBSERVER ID\", \"OBSERVATION DATE\", \"CARD\"]]\n",
    "\n",
    "    # Sort by card\n",
    "    card_valid.sort_values(by=\"CARD\", inplace=True)\n",
    "\n",
    "    return card_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_valid = chk2valid_card(chk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Card dataframe by aggregating all checklists\n",
    "\n",
    "We take back `chk` where all checklists (i.e., including the incidentals, stationary, etc...) and find if they contribute to an existing full card.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_card2chk_card(chk, card_valid):\n",
    "    # Create Card dataframe by aggregating all checklists\n",
    "    # We take back `chk` where all checklists (i.e., including the incidentals, stationary, etc...) and find if they contribute to an existing full card.\n",
    "    # Filter for checklist to keep: within pentad and and pentad and observer present in the valid card list\n",
    "    chk_keep = chk[\n",
    "        (chk[\"KEEP PENTAD\"])\n",
    "        & (\n",
    "            (chk[\"PENTAD\"] + chk[\"OBSERVER ID\"]).isin(\n",
    "                (card_valid[\"PENTAD\"] + card_valid[\"OBSERVER ID\"])\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Combine all possible checklits with the valid card based on observer and pentad.\n",
    "    # This will create duplicate checklist with all cards submitted by the same observer, same pentad, but any date\n",
    "    chk_card = pd.merge(\n",
    "        chk_keep,  # .loc[:,['OBSERVER ID', 'PENTAD', \"SAMPLING EVENT IDENTIFIER\", \"OBSERVATION DATE\"]],\n",
    "        card_valid,\n",
    "        on=[\"OBSERVER ID\", \"PENTAD\"],\n",
    "        suffixes=(\"_chk\", \"_card\"),\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # Filter the checklist for checklist beeing within the 5 days of the card so that there will be a single checklist-card now\n",
    "    duration = (\n",
    "        chk_card[\"OBSERVATION DATE_chk\"] - chk_card[\"OBSERVATION DATE_card\"]\n",
    "    ).dt.days\n",
    "    chk_card = chk_card[(duration >= 0) & (duration < 5)]\n",
    "\n",
    "    return chk_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_card = valid_card2chk_card(chk, card_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build card_chk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chk_card2card_chk(chk_card, card_valid):\n",
    "\n",
    "    # Cretate the card list with all checklists that belong to it. Compute aggregated value of all checklists\n",
    "    card_chk = (\n",
    "        chk_card.groupby(\"CARD\")\n",
    "        .agg(\n",
    "            {\n",
    "                \"SAMPLING EVENT IDENTIFIER\": list,\n",
    "                \"OBSERVATION DATETIME\": [\"min\", \"max\"],\n",
    "                \"DURATION MINUTES\": \"sum\",\n",
    "                \"EFFORT DISTANCE KM\": \"sum\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    card_chk.columns = [\"_\".join(col).strip(\"_\") for col in card_chk.columns.values]\n",
    "\n",
    "    # merge with the information contained in card_valid\n",
    "    card_chk = pd.merge(card_chk, card_valid, on=\"CARD\", how=\"inner\")\n",
    "\n",
    "    return card_chk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_chk = chk_card2card_chk(chk_card, card_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve species information per card\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chk_card2ebd_f_u(ebd, chk_card):\n",
    "    # Filter the full dataset to get only the checklist used in the card data\n",
    "    ebd_f = ebd.loc[\n",
    "        ebd[\"SAMPLING EVENT IDENTIFIER\"].isin(chk_card[\"SAMPLING EVENT IDENTIFIER\"]),\n",
    "        [\n",
    "            \"SAMPLING EVENT IDENTIFIER\",\n",
    "            \"SCIENTIFIC NAME\",\n",
    "            \"TAXON CONCEPT ID\",\n",
    "            \"ADU\",\n",
    "            \"OBSERVATION DATETIME\",\n",
    "            \"LATITUDE\",\n",
    "            \"LONGITUDE\",\n",
    "            \"EFFORT DISTANCE KM\",\n",
    "        ],\n",
    "    ]\n",
    "\n",
    "    # Add card_id\n",
    "    ebd_f = pd.merge(\n",
    "        ebd_f,\n",
    "        chk_card.loc[:, [\"SAMPLING EVENT IDENTIFIER\", \"CARD\"]],\n",
    "        on=\"SAMPLING EVENT IDENTIFIER\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # Keep a unique list of card-species (remove duplicate species in the same card, keeping the first one in time)\n",
    "    ebd_f.sort_values(\n",
    "        by=\"OBSERVATION DATETIME\", inplace=True\n",
    "    )  # SHould have been done already above, but necessary for keep=\"first\"\n",
    "\n",
    "    ebd_f_u = ebd_f.drop_duplicates(\n",
    "        subset=[\"CARD\", \"TAXON CONCEPT ID\"], keep=\"first\"\n",
    "    ).copy()\n",
    "    ebd_f_u.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Compute the sequence of records based on datetime entry\n",
    "    # ebd_f_u[\"SEQ\"] = (\n",
    "    #    ebd_f_u.groupby(\"CARD\")[\"OBSERVATION DATETIME\"].rank(method=\"min\").astype(int)\n",
    "    # )\n",
    "\n",
    "    # Compute the sequence basd on taxonomical order\n",
    "    ebd_f_u[\"SEQ\"] = (\n",
    "        ebd_f_u.groupby(\"CARD\")[\"TAXON CONCEPT ID\"]\n",
    "        .rank(method=\"min\")\n",
    "        .fillna(-1)\n",
    "        .astype(int)\n",
    "    )\n",
    "\n",
    "    # Not sure why, but fillina NA by nothing\n",
    "    ebd_f_u[\"EFFORT DISTANCE KM\"] = ebd_f_u[\"EFFORT DISTANCE KM\"].fillna(\"\")\n",
    "\n",
    "    # Convert datetime to standard format\n",
    "    ebd_f_u[\"OBSERVATION DATETIME\"] = ebd_f_u[\"OBSERVATION DATETIME\"].dt.strftime(\n",
    "        \"%Y-%m-%dT%H:%M:%SZ\"\n",
    "    )\n",
    "\n",
    "    return ebd_f_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebd_f_u = chk_card2ebd_f_u(ebd, chk_card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TAXON CONCEPT ID</th>\n",
       "      <th>SCIENTIFIC NAME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>OBSERVATION DATE</th>\n",
       "      <th>TIME OBSERVATIONS STARTED</th>\n",
       "      <th>OBSERVER ID</th>\n",
       "      <th>SAMPLING EVENT IDENTIFIER</th>\n",
       "      <th>PROTOCOL TYPE</th>\n",
       "      <th>DURATION MINUTES</th>\n",
       "      <th>EFFORT DISTANCE KM</th>\n",
       "      <th>ALL SPECIES REPORTED</th>\n",
       "      <th>OBSERVATION DATETIME</th>\n",
       "      <th>ADU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>species</td>\n",
       "      <td>avibase-7EE005BD</td>\n",
       "      <td>Phaethon aethereus</td>\n",
       "      <td>16.012736</td>\n",
       "      <td>-23.852151</td>\n",
       "      <td>1832-01-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>obsr939641</td>\n",
       "      <td>S126285649</td>\n",
       "      <td>Historical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1832-01-23 00:00:00</td>\n",
       "      <td>953.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>species</td>\n",
       "      <td>avibase-E6536E4E</td>\n",
       "      <td>Larus dominicanus</td>\n",
       "      <td>-24.639209</td>\n",
       "      <td>14.530987</td>\n",
       "      <td>1845-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>obsr4458114</td>\n",
       "      <td>S151363283</td>\n",
       "      <td>Historical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1845-10-01 00:00:00</td>\n",
       "      <td>287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>species</td>\n",
       "      <td>avibase-9B183BDD</td>\n",
       "      <td>Spheniscus demersus</td>\n",
       "      <td>-24.639209</td>\n",
       "      <td>14.530987</td>\n",
       "      <td>1845-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>obsr4458114</td>\n",
       "      <td>S151363283</td>\n",
       "      <td>Historical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1845-10-01 00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>species</td>\n",
       "      <td>avibase-AE61BF48</td>\n",
       "      <td>Phalacrocorax capensis</td>\n",
       "      <td>-24.639209</td>\n",
       "      <td>14.530987</td>\n",
       "      <td>1845-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>obsr4458114</td>\n",
       "      <td>S151363283</td>\n",
       "      <td>Historical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1845-10-01 00:00:00</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>species</td>\n",
       "      <td>avibase-775E93D7</td>\n",
       "      <td>Morus capensis</td>\n",
       "      <td>-24.639209</td>\n",
       "      <td>14.530987</td>\n",
       "      <td>1845-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>obsr4458114</td>\n",
       "      <td>S151363283</td>\n",
       "      <td>Historical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1845-10-01 00:00:00</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21190162</th>\n",
       "      <td>species</td>\n",
       "      <td>avibase-79A45DAF</td>\n",
       "      <td>Andropadus importunus</td>\n",
       "      <td>-4.418870</td>\n",
       "      <td>39.511232</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>21:08:00</td>\n",
       "      <td>obsr640800</td>\n",
       "      <td>S189700405</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-07-31 21:08:00</td>\n",
       "      <td>551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21190163</th>\n",
       "      <td>species</td>\n",
       "      <td>avibase-49D9148A</td>\n",
       "      <td>Ardea alba</td>\n",
       "      <td>-4.418870</td>\n",
       "      <td>39.511232</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>21:08:00</td>\n",
       "      <td>obsr640800</td>\n",
       "      <td>S189700405</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-07-31 21:08:00</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21190164</th>\n",
       "      <td>species</td>\n",
       "      <td>avibase-550DE745</td>\n",
       "      <td>Threskiornis aethiopicus</td>\n",
       "      <td>-4.418870</td>\n",
       "      <td>39.511232</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>21:08:00</td>\n",
       "      <td>obsr640800</td>\n",
       "      <td>S189700405</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-07-31 21:08:00</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21190165</th>\n",
       "      <td>species</td>\n",
       "      <td>avibase-6429024D</td>\n",
       "      <td>Ardea cinerea</td>\n",
       "      <td>-4.418870</td>\n",
       "      <td>39.511232</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>21:08:00</td>\n",
       "      <td>obsr640800</td>\n",
       "      <td>S189700405</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-07-31 21:08:00</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21190166</th>\n",
       "      <td>species</td>\n",
       "      <td>avibase-2E6575A8</td>\n",
       "      <td>Strix woodfordii</td>\n",
       "      <td>0.304880</td>\n",
       "      <td>32.608814</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>21:10:00</td>\n",
       "      <td>obsr1377183</td>\n",
       "      <td>S189699949</td>\n",
       "      <td>Incidental</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-31 21:10:00</td>\n",
       "      <td>362.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21190167 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CATEGORY  TAXON CONCEPT ID           SCIENTIFIC NAME   LATITUDE  \\\n",
       "0         species  avibase-7EE005BD        Phaethon aethereus  16.012736   \n",
       "1         species  avibase-E6536E4E         Larus dominicanus -24.639209   \n",
       "2         species  avibase-9B183BDD       Spheniscus demersus -24.639209   \n",
       "3         species  avibase-AE61BF48    Phalacrocorax capensis -24.639209   \n",
       "4         species  avibase-775E93D7            Morus capensis -24.639209   \n",
       "...           ...               ...                       ...        ...   \n",
       "21190162  species  avibase-79A45DAF     Andropadus importunus  -4.418870   \n",
       "21190163  species  avibase-49D9148A                Ardea alba  -4.418870   \n",
       "21190164  species  avibase-550DE745  Threskiornis aethiopicus  -4.418870   \n",
       "21190165  species  avibase-6429024D             Ardea cinerea  -4.418870   \n",
       "21190166  species  avibase-2E6575A8          Strix woodfordii   0.304880   \n",
       "\n",
       "          LONGITUDE OBSERVATION DATE TIME OBSERVATIONS STARTED  OBSERVER ID  \\\n",
       "0        -23.852151       1832-01-23                       NaN   obsr939641   \n",
       "1         14.530987       1845-10-01                       NaN  obsr4458114   \n",
       "2         14.530987       1845-10-01                       NaN  obsr4458114   \n",
       "3         14.530987       1845-10-01                       NaN  obsr4458114   \n",
       "4         14.530987       1845-10-01                       NaN  obsr4458114   \n",
       "...             ...              ...                       ...          ...   \n",
       "21190162  39.511232       2024-07-31                  21:08:00   obsr640800   \n",
       "21190163  39.511232       2024-07-31                  21:08:00   obsr640800   \n",
       "21190164  39.511232       2024-07-31                  21:08:00   obsr640800   \n",
       "21190165  39.511232       2024-07-31                  21:08:00   obsr640800   \n",
       "21190166  32.608814       2024-07-31                  21:10:00  obsr1377183   \n",
       "\n",
       "         SAMPLING EVENT IDENTIFIER PROTOCOL TYPE  DURATION MINUTES  \\\n",
       "0                       S126285649    Historical               NaN   \n",
       "1                       S151363283    Historical               NaN   \n",
       "2                       S151363283    Historical               NaN   \n",
       "3                       S151363283    Historical               NaN   \n",
       "4                       S151363283    Historical               NaN   \n",
       "...                            ...           ...               ...   \n",
       "21190162                S189700405    Stationary              60.0   \n",
       "21190163                S189700405    Stationary              60.0   \n",
       "21190164                S189700405    Stationary              60.0   \n",
       "21190165                S189700405    Stationary              60.0   \n",
       "21190166                S189699949    Incidental               NaN   \n",
       "\n",
       "          EFFORT DISTANCE KM  ALL SPECIES REPORTED OBSERVATION DATETIME    ADU  \n",
       "0                        NaN                     0  1832-01-23 00:00:00  953.0  \n",
       "1                        NaN                     0  1845-10-01 00:00:00  287.0  \n",
       "2                        NaN                     0  1845-10-01 00:00:00    2.0  \n",
       "3                        NaN                     0  1845-10-01 00:00:00   48.0  \n",
       "4                        NaN                     0  1845-10-01 00:00:00   44.0  \n",
       "...                      ...                   ...                  ...    ...  \n",
       "21190162                 NaN                     1  2024-07-31 21:08:00  551.0  \n",
       "21190163                 NaN                     1  2024-07-31 21:08:00   58.0  \n",
       "21190164                 NaN                     1  2024-07-31 21:08:00   81.0  \n",
       "21190165                 NaN                     1  2024-07-31 21:08:00   54.0  \n",
       "21190166                 NaN                     0  2024-07-31 21:10:00  362.0  \n",
       "\n",
       "[21190167 rows x 15 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebd_f_u2card_exp(card_chk, ebd_f_u):\n",
    "\n",
    "    # Extract the species list per card as a cell for vectorized computation\n",
    "    card_sp = (\n",
    "        ebd_f_u.groupby(\"CARD\")[\n",
    "            [\n",
    "                \"TAXON CONCEPT ID\",\n",
    "                \"ADU\",\n",
    "                \"SEQ\",\n",
    "                \"LATITUDE\",\n",
    "                \"LONGITUDE\",\n",
    "                \"OBSERVATION DATETIME\",\n",
    "                \"EFFORT DISTANCE KM\",\n",
    "            ]\n",
    "        ]\n",
    "        .agg(list)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Merge the card information by checklist and species into an export card dataframe\n",
    "    card_exp = pd.merge(\n",
    "        card_chk,\n",
    "        card_sp,\n",
    "        on=\"CARD\",\n",
    "    )\n",
    "\n",
    "    # Set some default values\n",
    "    card_exp[\"Protocol\"] = \"F\"\n",
    "    card_exp[\"ObserverEmail\"] = \"kenyabirdmap@naturekenya.org\"\n",
    "    card_exp[\"ObserverNo\"] = \"22829\"\n",
    "\n",
    "    card_exp[\"Hour1\"] = \"\"\n",
    "    card_exp[\"Hour2\"] = \"\"\n",
    "    card_exp[\"Hour3\"] = \"\"\n",
    "    card_exp[\"Hour4\"] = \"\"\n",
    "    card_exp[\"Hour5\"] = \"\"\n",
    "    card_exp[\"Hour6\"] = \"\"\n",
    "    card_exp[\"Hour7\"] = \"\"\n",
    "    card_exp[\"Hour8\"] = \"\"\n",
    "    card_exp[\"Hour9\"] = \"\"\n",
    "    card_exp[\"Hour10\"] = \"\"\n",
    "    card_exp[\"InclNight\"] = \"0\"\n",
    "    card_exp[\"AllHabitats\"] = \"0\"\n",
    "\n",
    "    card_exp[\"TotalHours\"] = round(card_exp[\"DURATION MINUTES_sum\"] / 60, 2)\n",
    "    card_exp[\"TotalDistance\"] = round(card_exp[\"EFFORT DISTANCE KM_sum\"], 2)\n",
    "    card_exp[\"TotalSpp\"] = card_exp[\"ADU\"].apply(lambda x: len(x))\n",
    "    card_exp[\"StartDate\"] = card_exp[\"OBSERVATION DATETIME_min\"].dt.date.apply(str)\n",
    "    card_exp[\"EndDate\"] = card_exp[\"OBSERVATION DATETIME_max\"].dt.date.apply(str)\n",
    "    card_exp[\"StartTime\"] = card_exp[\"OBSERVATION DATETIME_min\"].dt.strftime(\"%H:%M\")\n",
    "\n",
    "    # Function that generate species record to be used for each species of each card\n",
    "    def create_records(\n",
    "        TAXON_CONCEPT_ID,\n",
    "        ADU,\n",
    "        SEQ,\n",
    "        LATITUDE,\n",
    "        LONGITUDE,\n",
    "        OBSERVATION_DATETIME,\n",
    "        EFFORT_DISTANCE_KM,\n",
    "        CARD,\n",
    "    ):\n",
    "        return [\n",
    "            {\n",
    "                \"Sequence\": SEQ,\n",
    "                \"Latitude\": LATITUDE,\n",
    "                \"Longitude\": LONGITUDE,\n",
    "                \"Altitude\": \"\",\n",
    "                \"CardNo\": CARD,\n",
    "                \"Spp\": ADU,\n",
    "                \"SourceSpp\": TAXON_CONCEPT_ID,\n",
    "                \"Accuracy\": EFFORT_DISTANCE_KM * 1000,\n",
    "                \"SightingTime\": OBSERVATION_DATETIME,\n",
    "            }\n",
    "            for TAXON_CONCEPT_ID, ADU, SEQ, LATITUDE, LONGITUDE, OBSERVATION_DATETIME, EFFORT_DISTANCE_KM in zip(\n",
    "                TAXON_CONCEPT_ID,\n",
    "                ADU,\n",
    "                SEQ,\n",
    "                LATITUDE,\n",
    "                LONGITUDE,\n",
    "                OBSERVATION_DATETIME,\n",
    "                EFFORT_DISTANCE_KM,\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    # Apply the function\n",
    "    card_exp[\"records\"] = card_exp.apply(\n",
    "        lambda row: create_records(\n",
    "            row[\"TAXON CONCEPT ID\"],\n",
    "            row[\"ADU\"],\n",
    "            row[\"SEQ\"],\n",
    "            row[\"LATITUDE\"],\n",
    "            row[\"LONGITUDE\"],\n",
    "            row[\"OBSERVATION DATETIME\"],\n",
    "            row[\"EFFORT DISTANCE KM\"],\n",
    "            row[\"CARD\"],\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Rename to match ABAP server input\n",
    "    card_exp = card_exp.rename(\n",
    "        columns={\n",
    "            \"CARD\": \"CardNo\",\n",
    "            \"PENTAD\": \"Pentad\",\n",
    "            \"SAMPLING EVENT IDENTIFIER\": \"Checklists\",\n",
    "            \"OBSERVER ID\": \"ObserverNoEbird\",\n",
    "            \"SAMPLING EVENT IDENTIFIER_list\": \"Checklists\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    card_exp = card_exp.reindex(\n",
    "        columns=[\n",
    "            \"Protocol\",\n",
    "            \"ObserverEmail\",\n",
    "            \"CardNo\",\n",
    "            \"StartDate\",\n",
    "            \"EndDate\",\n",
    "            \"StartTime\",\n",
    "            \"Pentad\",\n",
    "            \"ObserverNo\",\n",
    "            \"TotalHours\",\n",
    "            \"Hour1\",\n",
    "            \"Hour2\",\n",
    "            \"Hour3\",\n",
    "            \"Hour4\",\n",
    "            \"Hour5\",\n",
    "            \"Hour6\",\n",
    "            \"Hour7\",\n",
    "            \"Hour8\",\n",
    "            \"Hour9\",\n",
    "            \"Hour10\",\n",
    "            \"TotalSpp\",\n",
    "            \"InclNight\",\n",
    "            \"AllHabitats\",\n",
    "            \"Checklists\",\n",
    "            \"TotalDistance\",\n",
    "            \"ObserverNoEbird\",\n",
    "            \"records\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return card_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'fillna'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m card_exp \u001b[38;5;241m=\u001b[39m ebd_f_u2card_exp(card_chk, ebd_f_u)\n",
      "Cell \u001b[0;32mIn[46], line 87\u001b[0m, in \u001b[0;36mebd_f_u2card_exp\u001b[0;34m(card_chk, ebd_f_u)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m     64\u001b[0m         {\n\u001b[1;32m     65\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequence\u001b[39m\u001b[38;5;124m\"\u001b[39m: SEQ,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m         )\n\u001b[1;32m     84\u001b[0m     ]\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Apply the function\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m card_exp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m card_exp\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: create_records(\n\u001b[1;32m     89\u001b[0m         row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTAXON CONCEPT ID\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     90\u001b[0m         row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADU\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m),\n\u001b[1;32m     91\u001b[0m         row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSEQ\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     92\u001b[0m         row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLATITUDE\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     93\u001b[0m         row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLONGITUDE\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     94\u001b[0m         row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOBSERVATION DATETIME\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     95\u001b[0m         row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEFFORT DISTANCE KM\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     96\u001b[0m         row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCARD\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     97\u001b[0m     ),\n\u001b[1;32m     98\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     99\u001b[0m )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# Rename to match ABAP server input\u001b[39;00m\n\u001b[1;32m    102\u001b[0m card_exp \u001b[38;5;241m=\u001b[39m card_exp\u001b[38;5;241m.\u001b[39mrename(\n\u001b[1;32m    103\u001b[0m     columns\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCARD\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCardNo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m     }\n\u001b[1;32m    110\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[46], line 90\u001b[0m, in \u001b[0;36mebd_f_u2card_exp.<locals>.<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m     64\u001b[0m         {\n\u001b[1;32m     65\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequence\u001b[39m\u001b[38;5;124m\"\u001b[39m: SEQ,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m         )\n\u001b[1;32m     84\u001b[0m     ]\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Apply the function\u001b[39;00m\n\u001b[1;32m     87\u001b[0m card_exp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m card_exp\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: create_records(\n\u001b[1;32m     89\u001b[0m         row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTAXON CONCEPT ID\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m---> 90\u001b[0m         row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADU\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m),\n\u001b[1;32m     91\u001b[0m         row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSEQ\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     92\u001b[0m         row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLATITUDE\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     93\u001b[0m         row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLONGITUDE\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     94\u001b[0m         row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOBSERVATION DATETIME\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     95\u001b[0m         row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEFFORT DISTANCE KM\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     96\u001b[0m         row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCARD\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     97\u001b[0m     ),\n\u001b[1;32m     98\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     99\u001b[0m )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# Rename to match ABAP server input\u001b[39;00m\n\u001b[1;32m    102\u001b[0m card_exp \u001b[38;5;241m=\u001b[39m card_exp\u001b[38;5;241m.\u001b[39mrename(\n\u001b[1;32m    103\u001b[0m     columns\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCARD\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCardNo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m     }\n\u001b[1;32m    110\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'fillna'"
     ]
    }
   ],
   "source": [
    "card_exp = ebd_f_u2card_exp(card_chk, ebd_f_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Sequence': 18,\n",
       "  'Latitude': -0.0392179,\n",
       "  'Longitude': 9.340437,\n",
       "  'Altitude': '',\n",
       "  'CardNo': '0000_0920_r431479_20220810',\n",
       "  'Spp': 3852.0,\n",
       "  'SourceSpp': 'avibase-E10D0809',\n",
       "  'Accuracy': 800.0,\n",
       "  'SightingTime': '2022-08-10T11:55:00Z'},\n",
       " {'Sequence': 17,\n",
       "  'Latitude': -0.0392179,\n",
       "  'Longitude': 9.340437,\n",
       "  'Altitude': '',\n",
       "  'CardNo': '0000_0920_r431479_20220810',\n",
       "  'Spp': 385.0,\n",
       "  'SourceSpp': 'avibase-D209A90C',\n",
       "  'Accuracy': 800.0,\n",
       "  'SightingTime': '2022-08-10T11:55:00Z'},\n",
       " {'Sequence': 5,\n",
       "  'Latitude': -0.0392179,\n",
       "  'Longitude': 9.340437,\n",
       "  'Altitude': '',\n",
       "  'CardNo': '0000_0920_r431479_20220810',\n",
       "  'Spp': 1152.0,\n",
       "  'SourceSpp': 'avibase-20D915AD',\n",
       "  'Accuracy': 800.0,\n",
       "  'SightingTime': '2022-08-10T11:55:00Z'},\n",
       " {'Sequence': 16,\n",
       "  'Latitude': -0.0392179,\n",
       "  'Longitude': 9.340437,\n",
       "  'Altitude': '',\n",
       "  'CardNo': '0000_0920_r431479_20220810',\n",
       "  'Spp': 576.0,\n",
       "  'SourceSpp': 'avibase-CF2E9674',\n",
       "  'Accuracy': 800.0,\n",
       "  'SightingTime': '2022-08-10T11:55:00Z'},\n",
       " {'Sequence': 15,\n",
       "  'Latitude': -0.0392179,\n",
       "  'Longitude': 9.340437,\n",
       "  'Altitude': '',\n",
       "  'CardNo': '0000_0920_r431479_20220810',\n",
       "  'Spp': 629.0,\n",
       "  'SourceSpp': 'avibase-AEE2063F',\n",
       "  'Accuracy': 800.0,\n",
       "  'SightingTime': '2022-08-10T11:55:00Z'},\n",
       " {'Sequence': 3,\n",
       "  'Latitude': -0.0392179,\n",
       "  'Longitude': 9.340437,\n",
       "  'Altitude': '',\n",
       "  'CardNo': '0000_0920_r431479_20220810',\n",
       "  'Spp': 510.0,\n",
       "  'SourceSpp': 'avibase-1AED683B',\n",
       "  'Accuracy': 800.0,\n",
       "  'SightingTime': '2022-08-10T11:55:00Z'},\n",
       " {'Sequence': 2,\n",
       "  'Latitude': -0.0392179,\n",
       "  'Longitude': 9.340437,\n",
       "  'Altitude': '',\n",
       "  'CardNo': '0000_0920_r431479_20220810',\n",
       "  'Spp': 594.0,\n",
       "  'SourceSpp': 'avibase-14AFBA82',\n",
       "  'Accuracy': 800.0,\n",
       "  'SightingTime': '2022-08-10T11:55:00Z'},\n",
       " {'Sequence': 11,\n",
       "  'Latitude': -0.0392179,\n",
       "  'Longitude': 9.340437,\n",
       "  'Altitude': '',\n",
       "  'CardNo': '0000_0920_r431479_20220810',\n",
       "  'Spp': 11491.0,\n",
       "  'SourceSpp': 'avibase-6ABDB635',\n",
       "  'Accuracy': 800.0,\n",
       "  'SightingTime': '2022-08-10T11:55:00Z'},\n",
       " {'Sequence': 12,\n",
       "  'Latitude': -0.0392179,\n",
       "  'Longitude': 9.340437,\n",
       "  'Altitude': '',\n",
       "  'CardNo': '0000_0920_r431479_20220810',\n",
       "  'Spp': 499.0,\n",
       "  'SourceSpp': 'avibase-97E7A30B',\n",
       "  'Accuracy': 800.0,\n",
       "  'SightingTime': '2022-08-10T11:55:00Z'},\n",
       " {'Sequence': 19,\n",
       "  'Latitude': -0.0392179,\n",
       "  'Longitude': 9.340437,\n",
       "  'Altitude': '',\n",
       "  'CardNo': '0000_0920_r431479_20220810',\n",
       "  'Spp': 3040.0,\n",
       "  'SourceSpp': 'avibase-EBE56736',\n",
       "  'Accuracy': 1800.0,\n",
       "  'SightingTime': '2022-08-10T13:56:00Z'},\n",
       " {'Sequence': 7,\n",
       "  'Latitude': -0.0392179,\n",
       "  'Longitude': 9.340437,\n",
       "  'Altitude': '',\n",
       "  'CardNo': '0000_0920_r431479_20220810',\n",
       "  'Spp': 1572.0,\n",
       "  'SourceSpp': 'avibase-32E6DB03',\n",
       "  'Accuracy': 1800.0,\n",
       "  'SightingTime': '2022-08-10T13:56:00Z'},\n",
       " {'Sequence': 14,\n",
       "  'Latitude': -0.0392179,\n",
       "  'Longitude': 9.340437,\n",
       "  'Altitude': '',\n",
       "  'CardNo': '0000_0920_r431479_20220810',\n",
       "  'Spp': 1584.0,\n",
       "  'SourceSpp': 'avibase-A90C512F',\n",
       "  'Accuracy': 1800.0,\n",
       "  'SightingTime': '2022-08-10T13:56:00Z'},\n",
       " {'Sequence': 4,\n",
       "  'Latitude': -0.0392179,\n",
       "  'Longitude': 9.340437,\n",
       "  'Altitude': '',\n",
       "  'CardNo': '0000_0920_r431479_20220810',\n",
       "  'Spp': 3700.0,\n",
       "  'SourceSpp': 'avibase-1DD0949C',\n",
       "  'Accuracy': 1800.0,\n",
       "  'SightingTime': '2022-08-10T13:56:00Z'},\n",
       " {'Sequence': 13,\n",
       "  'Latitude': -0.0392179,\n",
       "  'Longitude': 9.340437,\n",
       "  'Altitude': '',\n",
       "  'CardNo': '0000_0920_r431479_20220810',\n",
       "  'Spp': 2104.0,\n",
       "  'SourceSpp': 'avibase-A16C3B99',\n",
       "  'Accuracy': 1800.0,\n",
       "  'SightingTime': '2022-08-10T13:56:00Z'},\n",
       " {'Sequence': 6,\n",
       "  'Latitude': -0.0392179,\n",
       "  'Longitude': 9.340437,\n",
       "  'Altitude': '',\n",
       "  'CardNo': '0000_0920_r431479_20220810',\n",
       "  'Spp': 3608.0,\n",
       "  'SourceSpp': 'avibase-23BEFB19',\n",
       "  'Accuracy': 1800.0,\n",
       "  'SightingTime': '2022-08-10T13:56:00Z'},\n",
       " {'Sequence': 8,\n",
       "  'Latitude': -0.0392179,\n",
       "  'Longitude': 9.340437,\n",
       "  'Altitude': '',\n",
       "  'CardNo': '0000_0920_r431479_20220810',\n",
       "  'Spp': 3644.0,\n",
       "  'SourceSpp': 'avibase-3D3EF8AC',\n",
       "  'Accuracy': 1800.0,\n",
       "  'SightingTime': '2022-08-10T13:56:00Z'},\n",
       " {'Sequence': 10,\n",
       "  'Latitude': -0.0392179,\n",
       "  'Longitude': 9.340437,\n",
       "  'Altitude': '',\n",
       "  'CardNo': '0000_0920_r431479_20220810',\n",
       "  'Spp': 503.0,\n",
       "  'SourceSpp': 'avibase-5ACC908D',\n",
       "  'Accuracy': 1800.0,\n",
       "  'SightingTime': '2022-08-10T13:56:00Z'},\n",
       " {'Sequence': 9,\n",
       "  'Latitude': -0.0392179,\n",
       "  'Longitude': 9.340437,\n",
       "  'Altitude': '',\n",
       "  'CardNo': '0000_0920_r431479_20220810',\n",
       "  'Spp': 1492.0,\n",
       "  'SourceSpp': 'avibase-4B8F7AF5',\n",
       "  'Accuracy': 1800.0,\n",
       "  'SightingTime': '2022-08-10T13:56:00Z'},\n",
       " {'Sequence': 1,\n",
       "  'Latitude': -0.0392179,\n",
       "  'Longitude': 9.340437,\n",
       "  'Altitude': '',\n",
       "  'CardNo': '0000_0920_r431479_20220810',\n",
       "  'Spp': 112.0,\n",
       "  'SourceSpp': 'avibase-14885C18',\n",
       "  'Accuracy': 1800.0,\n",
       "  'SightingTime': '2022-08-10T13:56:00Z'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_exp[\"records\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = card_exp.to_json(orient=\"records\", indent=2)\n",
    "with open(\n",
    "    f\"../export/ebd_AFR_rel{month}-{year}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    f.write(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export in better format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_chk.to_csv(\n",
    "    f\"../export/ebd_AFR_rel{month}-{year}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}_cards.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ebd_f_u[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCARD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADU\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSEQ\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../export/ebd_AFR_rel\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_records.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:3964\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3953\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3955\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3956\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3957\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3961\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3962\u001b[0m )\n\u001b[0;32m-> 3964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[1;32m   3965\u001b[0m     path_or_buf,\n\u001b[1;32m   3966\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   3967\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[1;32m   3968\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   3969\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m   3970\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m   3971\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[1;32m   3972\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   3973\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[1;32m   3974\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m   3975\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m   3976\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[1;32m   3977\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[1;32m   3978\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[1;32m   3979\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[1;32m   3980\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m   3981\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/csvs.py:270\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/csvs.py:275\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_body()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_chunk(start_i, end_i)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/csvs.py:320\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    317\u001b[0m slicer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(start_i, end_i)\n\u001b[1;32m    318\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc[slicer]\n\u001b[0;32m--> 320\u001b[0m res \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_get_values_for_csv(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[1;32m    321\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(res\u001b[38;5;241m.\u001b[39m_iter_column_arrays())\n\u001b[1;32m    323\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_get_values_for_csv(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:1399\u001b[0m, in \u001b[0;36mDataFrame._get_values_for_csv\u001b[0;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_values_for_csv\u001b[39m(\n\u001b[1;32m   1390\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1391\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1397\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1398\u001b[0m     \u001b[38;5;66;03m# helper used by to_csv\u001b[39;00m\n\u001b[0;32m-> 1399\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mget_values_for_csv(\n\u001b[1;32m   1400\u001b[0m         float_format\u001b[38;5;241m=\u001b[39mfloat_format,\n\u001b[1;32m   1401\u001b[0m         date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[1;32m   1402\u001b[0m         decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   1403\u001b[0m         na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   1404\u001b[0m         quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[1;32m   1405\u001b[0m     )\n\u001b[1;32m   1406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(mgr, axes\u001b[38;5;241m=\u001b[39mmgr\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:466\u001b[0m, in \u001b[0;36mBaseBlockManager.get_values_for_csv\u001b[0;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_values_for_csv\u001b[39m(\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, float_format, date_format, decimal, na_rep: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, quoting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    461\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m    462\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;124;03m    Convert values to native types (strings / python objects) that are used\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;124;03m    in formatting (repr / csv).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    467\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_values_for_csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    468\u001b[0m         na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m    469\u001b[0m         quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[1;32m    470\u001b[0m         float_format\u001b[38;5;241m=\u001b[39mfloat_format,\n\u001b[1;32m    471\u001b[0m         date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[1;32m    472\u001b[0m         decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m    473\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/blocks.py:780\u001b[0m, in \u001b[0;36mBlock.get_values_for_csv\u001b[0;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_values_for_csv\u001b[39m(\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, float_format, date_format, decimal, na_rep: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, quoting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    778\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Block:\n\u001b[1;32m    779\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"convert to our native types format\"\"\"\u001b[39;00m\n\u001b[0;32m--> 780\u001b[0m     result \u001b[38;5;241m=\u001b[39m get_values_for_csv(\n\u001b[1;32m    781\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m    782\u001b[0m         na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m    783\u001b[0m         quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[1;32m    784\u001b[0m         float_format\u001b[38;5;241m=\u001b[39mfloat_format,\n\u001b[1;32m    785\u001b[0m         date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[1;32m    786\u001b[0m         decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m    787\u001b[0m     )\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7873\u001b[0m, in \u001b[0;36mget_values_for_csv\u001b[0;34m(values, date_format, na_rep, quoting, float_format, decimal)\u001b[0m\n\u001b[1;32m   7871\u001b[0m         values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<U\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitemsize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 7873\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(values, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7875\u001b[0m values[mask] \u001b[38;5;241m=\u001b[39m na_rep\n\u001b[1;32m   7876\u001b[0m values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ebd_f_u[[\"CARD\", \"ADU\", \"SEQ\"]].to_csv(\n",
    "    f\"../export/ebd_AFR_rel{month}-{year}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}_records.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
